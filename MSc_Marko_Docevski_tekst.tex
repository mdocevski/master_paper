\chapter{Вовед}

Is AI truly creative?
The relationship between maths and music is long established, with formulas underpinning all kinds of musical genres, from black metal to Indonesian gamelan. Ada Lovelace, the 19th century mathematician acknowledged as the first computer programmer, recognised the artistic potential of machines in the 1840s, suggesting that computers “might compose elaborate and scientific pieces of music of any degree of complexity”.
Nearly 200 years later, computers can do just that, thanks to the development of AI and the power of neural networks. “It’s a pared down representation of the way some scientists believe a human brain works,” says Ed Newton-Rex, co-founder of Jukedeck, an AI music composition tool. “By passing in lots of pieces of music, it can start to assess which notes should follow other notes. You end up with a system where you can choose a starting point and the algorithm can make a bunch of choices. Eventually, it builds an understanding of how to create a piece of music.”
According to Ashkhen Zakharyan, a spokesperson for Aiva, there’s an analogy between this process and the way humans compose – after all, we are also a sum of our influences.
“We learn from other artists,” she says, “and we embark on a trial-and-error process during which we don’t always get the notes right. But then we use our musical knowledge and musical ear to correct ourselves.
“Aiva is the same, but the process is reduced from a couple of years to a couple of hours.”
Newton-Rex is less convinced about this parallel. “Humans have very complex influences, like emotion, and memory,” he says.
“There’s a great deal that goes into human composition that no one in AI has got anywhere near. But that doesn’t mean it’s not powerful.”
Whether AI is truly creative or merely generating a kind of pastiche, the music it produces certainly sounds authentic. But our appreciation of the skill and ingenuity of computer programmers doesn’t equate to being entertained, according to Mark d’Inverno, Professor of Computer Science at Goldsmiths, University of London.
“People working in AI are understandably excited about generating something that would be called art if a human did it,” he says. “But I don’t see any signs that we want to experience computational work as art. Art is partly about unpicking the human experience of the person who created it.”

Генерирање на музика и други типови на мултимедиска содржина се мошне популарни теми на истражување во денешно време. Во академијата и популарните дискусии се води дебата за возможноста на оспосбување на компјутерски систем да покаже знаци на креативност, како што може да се види во \cite{Ghedini2015}. Едната страна на дебатата тврди дека компјутерите нема да можат, барем не во скоро време, да креират ништо уникатно и имагинативно бидејќи сите компјутерски системи за креирање на музика би биле зависеле од некој модел изграден врз колекција од композици направени од човек, или пак правила/граматики креирани од човек. Ваквите системи би работеле со некаков произволно апстрактен и комплексен систем на комбинации и рекомбинации за креирање на нови дела. Ова може да се смета како клучен лимитирачки фактор за израз на имагинација и инвентивност. Другата страна на дебатата ова не го смета како ограничување, туку како неопходно зло, или како еволутивен чекор во развивање на компјутерска креативност, исто како што е и дел од развојот на секој човек. Најголемиот дел од луѓето стапуваат во контакт со музиката долго време пред да започнат самите да допринесат кон целокупното човечко творештво. Така во делата на секој човек може да се пронајдат влијанија од другите автори со чии дела имаат стапено во контакт. Имитацијата е основен елеменет во процесот на учење, како и форма на одавање почит. Врз основа на ова, пропонентите на компјутерската креативност тврдат дека ваквите огрничувања се во најлош случај само еволутивен чекор. (МОЖЕБИ ТРЕБА ДА СЕ РЕФОРМУЛИРА ПОУБАВО)

Андреј Карпати со статија „Неразумната ефективност на рекурентните невронски мрежи“ \cite{AndrejKarpathy2015} значително го зголеми интересот на полето на машинско учење, поточно на невронските мрежи и нивните рекурентните варијанти. Во статијата е прикажан генеративен јазичен модел на ниво на буква, составен од длабока невронска мрежа изградена од рекурентни ќелии (рекурентна невронска мрежа), истрениран на повеќе колекции на текстови од различен карактер (есеи од Пол Греам, драми од Шекспир, XML од Википедиа, LaTeX текстови и C\\C++ изворен код). Моделот ги учи текстовите буква по буква, и резултатот го генерира на истиот начин. Иако не му се додаваат никакви информации за структурата на текстовите, на јазикот, граматички правила или форматирање, тој успева да генерира резултати кои се конформираат во голема мера кон изворниот формат. Самиот креира ад-хок правила за конструкција на сложени зборови, генерирајки и сложени зборови што ги нема во изворните текстови, учи употреба на сврзници, честички, негации, сложени реченици иако не секогаш се поврзани просите реченици и сл. Во случајот каде што учи технички документи и изворен код ги прати и долгорочните зависности на отворање и соодветно затворења на загради и маркери кои често се простираат на растојание од повеќе стотини букви низ текстот. Успешноста на овој модел има инспирирано огромен број на истражувачи и луѓе од индустријата да се обидат да креираат генеративни модели со користење на рекурентни невронски мрежи со релативно едноставни архитектури. Дел од трудовите што ќе ги претставиме во наредното поглавје, вклучувајки го и нашиот се поттикнати од успехот на овој експеримент.

Покрај желбадата да придонесеме кон филозофксата дискусија за компјутерската креативност, увидовме и повеќе можности за практично искористување на систем за генеирање на музика, вклучувајки:
\begin{itemize}
\item Музика за видео игри, т.е. процедурално генерирана музика, кадешто музката ќе се адаптира на атмосферата и претходно дефинирани параметри, темпо и сл.
\item Музика за вежбање. Во принцип генерирање на музика што треба да следи предефинирани рутини за вежбање и ќе помага во одржување на темпо и енергетско ниво и ќе стимулира. Додатно ритамот и темпото на музиката може да бидат и под влијание на виталните знаци на корисникот, примарно пулс и дишење.
\item Компјутерски помогнато компонирање на музика. Човечки композитор користи апликација која му пружа можност за дополнување на музика, варијација на постоечка музика според параметри и тн.
\end{itemize}

Уште пред да започнеме со работа знаевме дека било каков генеративен систем со модели за машинско учење има огромен потенцијал за тесно грло бидејќи не постои начин за квалитативно оценување на излезот од таков моделот, т.е. не постои целна функција која што може да се оптимизира во процесот на учење. Во трудовите што ги проучивме, кои ќе ги разгледаме во поглавје {СТАВИ ЛИНК ДО ПОГЛАВЈЕ}, најчест пристап е рачна евалуација на резултатите од страна на човек, којшто во принцип е музички образован. Ваквото тесно грло не само што елиминира гаранција за квалитет на резултатите, туку и го ограничува изборот на алгоритми за машинско учење. 

Досегашните обиди за генерирање на музика може да се поделат на две категории: генерирање на пишана музика и генерирање на аудио сигнал. Пристапите за пишана музика значително варираат во комплексноста на проблемот што пробуваат да го решат, тргнувајќи од генеирање на „12 bar blues“ [ЦИТИРАЈ ЕК] блуз во 12 такти, до народна музика [ЦИТИРАЈ ФОЛК РНН], па се до Бахови корали во 4 гласа [ЦИТИРАЈ БАХБОТ И ОСТАЛИ]. Во другата категорија досегашните обиди [цитирај ВЕЈВНЕТ] се ограничени до учење на звучен сигнал од еден инструмент со ограничена должина, или работат со голема улога на човечки композитор [ЦИТИРАЈ СОНИ ЦСЛ ДЕДИС КАР]. Ние одлучувме да се зафатиме со проблемот на генерирање на пишана музика, поточно со полифона музика во еден глас. Додатни структурни ограничувања не сакавме да ставиме од самиот почеток, освен музиката да е од ист или сличен жанр и одеден или мал и ограничен број на автори.

Во трудот ќе ја прикажеме нашата работа на полето на генеративни музички модели која вклучува собирање и анализа на две посебни податочни множества, првото од дела за класична гитара во MIDI* формат, другото рачно изградено множество добиено со конверзија на GuitarPro табулатури за гитара како и повеќе експерименти со различни архитектури за машинско учење. Ги искористивме следниве архитектури во различни конфигурации: повеќеслојна LSTM* рекурентна невронска мрежа, повеќеслојна LSTM рекурентна невронска мрежа во комбинација со целосно поврзани слоеви и Encoder-Decoder архитектура изградена од LSTM слоеви. Ќе дадеме и толкување на добиените резултати, како и можностите за подобрување на системот што ги согледавме.

Трудот е организиран во следните поглавја: во поглавјето [ЦИТИРАЈ МОТИВАЦИЈА И ДЕФИНИЦИЈА НА ПРОБЛЕМОТ] ќе ја дадеме мотивацијата за превземање на истражувањето и ќе го дадеме дефиниција на задачата што сакаме да ја завршиме, во поглавјето [ЦИТИРАЈ ПРЕГЛЕД] даваме преглед на досегашните решенија и ќе ги споредиме со нашето решение, во поглавјето [ЦИТИРАЈ ДАТАСЕТ] ги опишуваме и даваме анализа на податочните множества што ги собравме, во под-поглавјето [ЦИТИРАЈ РЕПРЕЗЕНТАЦИЈА] ќе ги опишеме адаптациите на податочното множество за неговор користење со модели за машинско учење, во поглавјето [ЦИТИРАЈ АРХИТЕКТУРИ] ќе ги опишеме архитектурите за машинско учење што ги искористивме во експериментите, во поглавјето [ЦИТИРАЈ ЕКСПЕРИМЕНТИ] ќе опишеме експериментите што ги извршивме, во поглавјето [ЦИТИРАЈ РЕЗУЛТАТИТ] ќе ги опишеме и толкуваме резултатите од експериментите и во последното [ЦИТИРАЈ ЗАКЛУЧОК] поглавје ќе ги дадеме заклучоците од нашата работа опишана во овој труд, како и ќе ги забележиме можностите за подобрување кои ги увидовме.

\chapter{Преглед на литературата}

Еден од раните обид за „алгоритамско“ креирање на музика е познат како „Музички игри со коцки“, бил популарен во XVIII век. Првата забележана композиција создадена на овој начин е „Секогаш спремен минует и поноњески композитор“ (гер. Der allezeit fertige Menuetten- und Polonaisencomponist) од Јохан Филип Кирнбергер уште во 1757год. Најпопуларни биле игрите напишани од страна на Хајдн и Моцарт, поради што може да се пронајдат вакви игри и под името Моцартови коцки. Ваквуте игри најчесто се состојат од таблица од музички исечоци, во големина од еден до неколку такта, кои се напишани така да немаат остри рабови за да може лесно да се надоврзуваат. Играчите на играта фрлаат коцки или случајно избираат број, па според тоа избираат исечок од табелата според одредена шема која иде со табелта, и избраниот исечок го прилепуваат на композицијата. Играта трае се додека играчот не одлучи дека има доволно долга композиција. Квалитетот на добиената композиција зависи најмногу од квалитетот на исечоците. Бројот на можни исечоци мора да биде релативно мал за да може играчите да може практично да играат, а да не прелистуваат стотици страници секој пат кога ќе свртат коцка. Исечоците за да можат да бидат лесно поврзливи од двете страни практично треба да имаа почеток, средина и крај, т.е. да бидам самостојни микро-композиции. Поради сите овие ограничувања, Музичките игри со коцки повеќе се игра отколку практичен начин за алгоритамски пристап за компонирање музика. Доклку се решат сите ограничувања играта би добила многу поголем капацитет за креативност, меѓутоа би била непрактична за човечка употреба. Тука влегуваат во игра компутерски имплементации на играта. Скоро сите пристапи кои ги истражив може да се апстрахираат како играта врз основа на 2 клучни точки:
\begin{itemize}
    \item Дефиниција на исечок / Освноен елемент на композиција 
    \item Избор на исечок / Начин на прилепување на исечоците
\end{itemize}
Пристапите кои ги разгледав може се подделат во две епохи пред длабоко учење и со длабоко учење. Пред длабоко учење сите пристапи се доста блиски до игрите со коцки, поголем дел бараат само начин на заменување на процесот на избор на исечок со: правила и граматики, експертски системи, генетски алгоритми. Пристапите со длабоко учење се повеќе се оддалечуваат од игрите, но сепак суштински го вршат истото. 

\section{Граматички / експертски системи} 

Д. Коуп во трудот \cite{Cope1991} ја опишува првата компјутерска имплементација на музичките игри со коцки. Коцките се заменети со стохастички процес. Исечоците се претставени со шаблони, кои ги добиваат со делење на корпус од пишана музика, во должини од еден до два такта. Сите шаблони се анализираат спооред рачно пишани правила базирани на музичка теорија и содржат „потпис“ на авторот и се чуваат во лексикон. Случајниот процес бира од кандидат шаблони од лексиконот коишто се компатибилни со последниот избран шаблон. Компатибилоста ја одредуваат со анализа на тон и должина на ноти и со споредба на шаблони, којашто ја врши врз основа на релативно движење на тоновите и должините.

Импелемнтација на играта со генетски алгоритам може да се види во \cite{Biles1994}. Тука исечоците се претставени со хромозоми на алгоритмот. Музиката е во строг 4/4 ритам, секој хромозом е еден такт составен од 8 настани во должина од 1/8, при што настан може да бидат нова нота, задржување на стара нота и пауза. Квалитет на секој од хромозомите при процесот на еволуција се одредува рачно од страна на човечки ментор, кој венсува вредност со помош на тастатура. Ова е очигледна болна точка за практичноста на алгоритамот, што го прави алгоритамот крајно непрактичен, потребно е многу време за вешт ментор да ги преслушува кандидатите и да ги оценува. 

Во трудот \cite{Zils2001} авторите опишуваат експертски систем за креирање на мозаик од музички сегменти (исечоци). Сегментите се опишани со многжество на дескриптори. Дефинираат два вида на правила, сегментни, т.е. правила кои што се евалуираат на ниво на сегмент, и секвенцни, т.е. глобални правила, коишто се евалуираат на целата секвенца. Дел од правилата се преддефинирани, а дел корисникот на алгоритмот ги внесува рачно. Доклку сака корисникот може и да избере готова песна врз основа на која ќе се екстрахираат правила врз основа на кои ќе биде креирана нова песна, во суштина имитирајќи ја оригиналната песна од високо ниво. Бидејќи правилата не се секогаш се во согласување, авторите имаат и дефинирано постапка за евалуација на важноста на правилата врз основа на тежини, т.е. функција на чинење која ја минимизираат при процесот на генерирање.

Пристапот опишан во \cite{GarciaSalas2011} може наједонставно да се објасни како n-gram модел или модел со Маркови синџири. Системот се состои од дел за учење и дел за копонирање. Делот за учење генерира правила врз основа на податочното множество, а делот за компонирање генерира нова музика врз основа на правилата и има повратна врска кон делот за учење. Правилата се изразени преку 3 матрици: матрица на времетраења на нотите, локална матрица на фрекфенции и кумулативна матрица на фрекфенции. Овие матрици се пополнуваат според n-gram фрекфенции на појавување во податочното множество. Алгоритамот за генерирање пресметува матрица на веројатност на појавување како функција од претходно споменатите матрици. Генерирањето се врши со стохастичен процес врз основа на матрицата на веројатности. 

Уште еден систем за градење на музички мозаици може да се види во \cite{Schwarz2006}, каде авторите имаат изградено корпус од кратки исечоци, секој опишан со одредено множество на дескриптори, наголем дел добиени со математички трансформации на аудио сигналот, пр. брзи фуриеви трансформации, гаворови бранови, хистограми и сл. Системот има алгоритам за избирање на исечоци, кои последователно ги лепи едни за други за време на процесот на генерирање. Алгоритамот е базиран на човечки зададени правила или имитација на постоечки песни, кадешто алгоритамо само ги бира исечоците кои ги задоволуваат критериумите базирани на десктрипторите, без да води сметка за колку добро се сложуваат меѓусебе, и врши благо измазнување на краевиењ помеѓу исечоците.

\section{Алгоритми со длабоко учење} 

Голем број на алгоритми и техники измислени дури од самите почетоци на истражување на полето на машинско учење, како што се модели со невронски мрежи, машини со носечки вектори, дрва на одлука и сл., во минатото не покажува многу добри резултати во однос рачно изградени експертски модели. Најголемо ограничување беа пресметковната моќ и меморискиот капацитет на машините на коишто се извршуваа истите, влијаејќи на големината и комплексноста на моделите за машинско учење како и количината на податоци што може да се обработи при учење на истите. Меѓутоа во последните десетина години започнаа да се користат графичките акцелератори (попознати како графички картички), дотогаш највеќе користени за видео игри, за општа намена (GPGPU - General Purpouse GPU). Се појавија на сцена две библиотеки CUDA од NVIDIA Corp. и OpenCL - слободен софтвер развиен од заедницата на корисници, кои овозможуваат користење на графичките акцелератори за секакви пресметковни намени, што се покажа многу корисно за развивање на модели за машинско учење. Оттокаш се појави и експлозивен интерес за изстражување на секакви теми и решавање на секакви проблеми со користење машинско учење, вклучувајќи и модели за компјутерско генерирање на музика. Самото зголемување на пресметковна моќ овозможува создавање на многу подлабок, пософистициран и поапстрактен систем од тоа што го нудеа претходно споменатите техники. Во продолжение следуа преглед на повеќе пристапи за генерирање на музика со длабоко учење, кое претставува подмножество на техники за машинско учење со користење на длабоки невронски мрежи.

Првиот документиран обид за користење на невронски мрежи за генерирање на музика е од страна на Д. Ек во трудот \cite{Eck2002}. Целта е тренирање на модел кој ќе генерира блуз во 12 такта. Музиката се состои од 2 оделни компоненти, секвенца на акорди кои го одредуваат ритамот и ја даваат основната структура на музиката и мелодиска линија. Моделот има две групи од по 4 пара LSTM (Long Short Term Memory) ќелии (рекурентни неврони), од кои едната е задолжена за учење на мелодијата, а друга за акордната секвенца. Музиката ја преставуваат во тн. репрезентација во пиано лента, која е дво димензионална бинарна матрица во која едната оска (подолгата) го претставува времето, а другата оска го преставува множеството од можни тонови. Музиката има строга структура, 12 такта, 4/4 ритам и времето е подделено на 1/8 ноти. Моделот го испробале на два експерименти, во првиот тој ја учи само секвенцата на акорди, а во вториот и акордите и мелодијата. Тренирањето е извршено со cross-entropy фунција на загува, со сигмоидална функција на активација. Делот за учење на акорди ја споделува својата внатрешна состојба со делот за учење на мелодијата. Авторот смета дека системот генерира добра музика, но сепак проблемот што пробува да го реши е хипер фокусиран и ограничен. Трудот \cite{Eck2008} претставува надоградување на претходно опишаниот систем. Го нема веќе фокусот на блуз во 12 такти, туку работат со податочно множество од поразлини MIDI датотеки, зголемена е комплексноста на моделот, со многу повеќе ќелии и повеќе слоеви од истите. Додатно на моделот му прикажуваат и временски дилатирани копии од податоците, на семантички важни растојание. Ова доаѓа од хипотезата дека во музиката значајни настани се случуваат на метрички важни места како што се почетокот и крајот на тактовите, како и на моменти зависни од ритамо (пример во македонскиот 7/8 ритам ен-два, ен-два, ен-два-три, има значајни транзиции на секое „ен“). Ова го постигнуваат со проширување на пиано лентата да при секој чекор на моделот му се прикаже лентата од тековниата музика, и од музиката од претходно зададени интервали, како на пр. пред 1, 4 и 16 такта толно на истиот удар во тактовите. Покрај LSTM слоеви моделот има и паралелен целосно поврзан слој неврони којшто треба да помогне во учење на локални зависности меѓу нотите. Мрежата ги учи песните како една секвенца, со што грешката при учење се ресетира акумулираната грешка на граница меѓу песните. Нотите се ограничени помеѓу C3 и C5 и сите песни се транспонирани во ист клуч. Користени се ирски народни песни во 4/4 ритам. Моделот генерира нови песни со предвидување на следната нота откако ќе се припреми претходно со исечок од постоечка песна.

Во трудот \cite{Sturm2016} авторите користат техники од обработка на природни јазици за генерирање на музика. Караткеристична е употребата на форматот за музика познат како ABC. Форматот е текстуален, наменет примарно за запишување на изворна музика на едноставен и лесно разбирлив начин за луѓето, содржи мелодиска линија запишана со основни тонови и пропратен тескт. Музиката пишана во овој формат е опишана на високо ниво и доста стилски хомогена. Сите овие фактори ги прават форматот и податочното множество одлични за обработка со техники за обработка на природни јазици. Со користење на многу едноставен јазичен модел на ниво на буква и едноставна архитектура од 3 слоја од 512 LSTM неврони, со софтмакс активациски слој авторите добиле многу позитивни резултати. Во трудот прикажуаат и додатно подобрување на системот со повеќе чекори на предпроцесирање на текстот, користејки малку семантичко знаење, го трансформираат текстот од низа букви во низа уникатни и музички значајни токени врз основа на музичката функција на буквите/симболите. Додатно извршиле и процес на селекција и стандардизација на множеството песни за да ги исфрлат песните коишто се: премногу кратки, недволно информативни, конфузни или двосмислени; и го извршиле транскрипција на сите песни во ист клуч. Моделот е трениран со множество од над 23000 песни, во мини-бечови од 50 елементи, во 100 епохи. Генерирањето се врши со итеративна постапка, започнувајќи со посебен симбол за старт. Имаат извршено додатен експеримент во кој го стартуваат моделот со подолг извадок од песни од одредени автори за да ги проверат можностите на моделот да генерализира стилски карактеристки, и авторите тврдат дека моделот е способен за тоа.

Врз основа на техники за обработка на природни јазици може да се направат и модели на ниво на збор. Ваков пристап си има свои ограничувања бидејќи се зголему драстично бројот на основни елементи, има многу повеќе зборови одошто букви и симобили во јазициите, и нивните фрекфенции на појавување опаѓаат драстично. За да се надмине ова се користат различни техники за намалување на бројот на варијабли во системот, т.е. намалување на бројот на зборови, групирање на зборовите според функција, споделување на веројантности помеѓу зборовите и трансформации во помалку димензионален простор. Токму ваков пристап може да се види во \cite{Bretan2016}, каде што авторите третираат исечоци од 1 до 4 такта како зборови. Бидејќи има огромен број на можни варијации на таквите исечоци истите ги смалуваат во помалку димензионален простор користејќи ја техниката на вградување во латентен простор (анг. latent space embedding). Вградувањето го вршат врз основа на сет од дескриптори со кои ги опишуваат исечоците. Со ова се тобива структура налик на хеш табела, само со повеќе можни резултати при процесот на декодирање од елемент во табела во исечок. Тренираат два модела, еден што учи секвенци од репрезентации на зборовите, а друг што ги учи песните на ниво на буква и е наменет за решавање на проблемот на декодирање, т.е. ги гледа работиве помеѓу тековната секвенца и сите потенцијални декодирани исечоци, и помага во изворот на најсоодветниот кандидат. Намената на моделот на ниво на збор е да учи музички зависности на подолг временски период, во обид да се научи структура на цела песна, додека другиот модел ги учи локалните зависности помеѓу нотите. На крај извршиле субјективна евалуација од страна на 32 музички експеримент, коишто ги рангирале резултатите од повеќе инстанци на моделот со различн параметри.

Коралите на Јохан Себастијан Бах претставуваат интересен проблем за моделирање. Се стостојат од 4 гласна полифонија, алто, тенор, сопрано и бас монофонични мелодиски линии. Може да се моделираат на сличен начин како акордите, со тоа што зависностите помеѓу гласовите не е иста како меѓу нотите во акордите. Исто така уникатните комбинации од ноти по гласови поретко се јавуваат одошто кај акордите, бидејќи акордите се стандардни конструктивни елементи во музиката. Ова податочно множество е главен фокус на трудовите \cite{Liang2017, Hadjeres2016}. Во \cite{Liang2017} е искористен релативно еднсотавна архитектура, составена од повеќе рекурентни LSTM слоеви, со embedding слој после влезниот инспириран од word2vec\cite{Herremans2017}, со едноставен софтмакс активациски слој. Бидејќи ритамот во целото податочно множество е 4/4, музиката е поделена на еднакво долги рамки со времетраење 1/16-ка, во која 4те гласа се претставени со субсеквенца од поединечни ноти, а рамките меѓусебно се поделени со посебен симбол за разграничување. Со тоа се продолжува ја намалуваат комплексноста на проблемот за предвидување од $O(128^4)$ на $O(128)$, но ја издолжуваат секвенцата со фактор 5. Со алгоритам оптимизација на хиперпараметри GridSearch ги оптимизирале следните парамерти: број на рекурентни слоеви, големина на рекурентните слоеви, големина на embedding слојот, должина на секвенца што се користи за TBPT (анг. Truncated Back Propagation Through Time, Скратена повратна инфомација назад низ времето), процент за dropout (техника за нормализација, толкувано губиток на излезна информација). Во трудот \cite{Hadjeres2016} авторите користат посебни модели за секој од гласовите, и на крај ги сумираат нивните резултати. Ова влече одредена независност помеѓу гласовите, што во реалност секако не е точна, гласовите се функционално зависни помеѓусебе. За секој глас имаа модел составен од две рекурентни длабоки невронски мрежи, од кои едната го обработува времето наназад, а другата нанапред, и една целосно поврзана невронска мрежа која ги учи истровремено појавените ноти. Овие три подмрежи работат во паралела за секој временски чекор, и излезите од сите три се користат како влез во финална општа невронска мрежа која ги влече заклучоците за секој временски чекор. За генерирање користат псевдо-Гибсово семплирање (варијанта на Монте карло Маркови синџири), со кое влечат примероци од добиените излези од 4те подмодели за секој глас. Податочното множество го имаат транспонирано во сите можни клучеви наместо стандардизирање кон еден клуч. И во двата труда се прикажани процеси за субјективна оцена на резултатите со онлајн тестови каде што на корисниците им се пушта музички исечок и треба да одлучат дали е генерирана музика или оригинална композиција на Бах. Во двата случаја најпозитивни резултати покажале кога моделите ги користеле за рехармонизација на мелодија врз основа на 2 или 3 постоечки гласа.

Во системот наречен „Производ на експерти“ предложен во \cite{Johnson2017} се користат два прости јазични модели во тандем, тренирани на истото податочно множество од џез песни, со различен перпектива врз истото. Двата модела се едноставни рекурентни длабоки невронски мрежи, од кои едниот ги гледа песните како секвенца од релативно движење на мелодијата, т.е. при секој чекор ја гледа абсолутната разлика во тонот меѓу последователни ноти, додека другиот ја следи хармониската улога на нотата во тековниот акорд од прогесијата на акорди. Двата модели при секој чекор моделираат веројатностна дистрибуција и може едноставно да се тренираат со оптимизациски алгоритми за намалување на крос-ентропија, а финалниот резултат е параметризирана сума од двете. Тренирањето и генерирањето на песните следи стандардна итеративна процедура.

Користењето на јазични модели на ниво на бука овозможува едноставно моделирање на монофона музика, или музика која во секој момент има највеќе една активна нова. При моделирање на акорди со пиано лента се појавува проблем на енумерирање сите можни конфигурации на ноти што може да се појават, пр. за гитара има грубо $2*24^6$ можни конфигурации на ноти. Еден пристап за намалување на проблемите што доаѓаат од зголемена димензионалност може да се види во \cite{Boulanger-Lewandowski2012, Boulanger-Lewandowski2014, Goel2014}, каде што авторите користат хибридна архитектура, изграден од рекурентни невронски слоеви во различни комбинации со енергетски модели. Идејата е да се искористат особеностите на енергетските модели, како што се RBM (Restricted Boltzmann Machines - Ограничени Болзманови Машини) и NADE (Neural Autoregressive Distribution Estimator), да моделираат веројатностни дистрибуции, кон моделирање на истовремено појавување на нотите во акорди. Од \cite{Boulanger-Lewandowski2012, Boulanger-Lewandowski2014} произлегуваат моделите: RTRBM (Recurrent Temporal RBM - Рекурентна Темпорална Ограничена Болзманова Машина), RNN-RBM, RNN-NADE, од кои RNN-NADE се покажал како наједноставен за тренирање и со најдобри генеративни резултати и најекспресивен, иако од енергетските модели NADE има релативно помала експресивна моќ. Моделот може да се разбере како низа од условени енергетски слоеви, по еден за секој временски чекор што го обработува мрежата, со излез во детерминистички рекурентен невронски слој. Наголем проблем на овој тип на модели се покажала осетливоста на иницијална состојба, што многу ја потенцира важноста на пред-тренирање при нивна употреба. Моделот се покажал успешен во моделирање на локални зависности, хармониски правила и кратки мелодиски линии, меѓутоа не може да моделира долговременски зависности. Во \cite{Goel2014} авторите користат пософистицирана варијанта на RNN-RBM наречена RNN-DBN, во која секвенците од RBM слоеви се заменети со секвенци од длабоки подмрежи изградени од повеќе хиерахиски RBM слоеви. Не користат никакви техники за иницијализација на енергетските слоеви како во \cite{Boulanger-Lewandowski2012, Boulanger-Lewandowski2014, Goel2014} ниту за оптимизирање на работата на моделот.

Јазичните модели на ниво на буква може да се прошират на повеќе начини. Во трудот \cite{Tikhonov2017} авторите предложува збогатување на самите букви и користење на embedding или врадување на самите букви и на секвенци со одредена должина. Се ограничуваат со генерирање на монофонична музика, користејќи огромна колекција на MIDI датотеки, со низа чекори за филтрирање, одстранување на сувишни информации, транспозиции и уедначувања добиле податочно множество од повеќе од 15000 песни составени само од мелодиска линија. Секоја нота од мелодиската секвенца е претставена со embedding-зи за: висината, октавата и времетраењето како и со мета-информации извлечени од MIDI датотеката. Ваквата репрезентација ја кодираат во 1 од N бинарен вектор на влез, и на излезот од системот користат 1 од N софтмакс активација. Средниот дел од архитектурата се состои од енкодер и декодер длабока рекурентна подмрежа. Двете подмрежи се обратно свртени пирамиди кои се сретнуваа со врвовите, т.е. во енкодер во секој нареден слој се намалува бројот на неврони се додека да се стигне до крајниот слој наречен тесно грлчо. Така секој нареден слој ги компресира податоците во густа репрезентација. Во декодерот се случува обратното, секој нареден слој има повеќе неврони и тој го открива значењето на густата реперзенатиција. Излезот од декодерот оди во активацискиот слој. Песните се делат на подсеквенци и моделот ги учи нивните густи репрезентации и како да ги добие секвенците од нивните репрезентации. Архитектурата ја нарекле VRASH - Variational Recurrent Autoencoder Supported By History (Варијациски аутоенкодер поддржан од историја) и претставува обид за додавање на варијациски баесов шум кон јазичен модел со користење на рекурентен аутоенкодер.

Во трудот \cite{Oord2016} дефинираат архитектура за обработка и учење на аудио сигнал со користење на конволуциски невронски мрежи, наречен WaveNet. Новоста во архитектурата се додадените временски дилатации и условеност на мрежата. Дилатациите функционираат на тој начин што временски задоцнети копии од податоците им се предаваат на повисоките слоеви во одредени интервали. Пр. влезниот слој обработува податоци од моменти: $t$, $t-1$, $t-2$ и $t-4$, следниот од $t$, $t-1$ и $t-2$, а последниот само од $t$ и $t-1$. Мрежата се улосував со пресметување на условни веројатности при извршување на конволуциите врз основа на класа на звук што се обработува, нпр. кој го изговара звучниот сегмент, на кој инструмент е отсвирен и тн. Архитектурата се покажала со ограничено рецептивно поле од околу $1/4$ од секунда, па учи мошне кратки секвенци, но тоа го прави многу добро. Најголем недостаток на самата архитектура е многу големата пресметковна цена, моделот го тренираат со недели на компјутерски кластер и му треба повеќе од час да генерира една секунда аудио сигнал, а времето расте со бројот на елементи во архитектурата (неврони по слој, број на слоеви).

Во трудот \cite{Mehri2016} авторите предложуваат хиерархија од модели за учење на музка од аудио сигнал. Најниското ниво обработува рамки со големи од еден примерок, а секое нагорно ниво обработува се поголеми рамки, или подолги временски периоди, без преклоп. Сите нивоа освен најниското се длабоки рекурентни невронски мрежи, а најниското ниво е повеќеслојна перцептрон мрежа. Погорните слоеви влијајат на подолните, така што нивните излези се користат како влез на пониско ниво, слично на деконволуција. Најнискиот слој генерира дистрибуција врз просторот на можни примероци во наредниот временски момент. Целата хиерархија се тренира во целост крај-до-крај. Извршиле AB тест за субјектина оцена, споредувајќи го дво и трослојна варијанта на моделот со нивна квази-имплементација на WaveNet \cite{Oord2016} и едноставен рекурентен модел, од кои тврдат дека 3 слојниот модел е префериран од страна на оценувачите.

Многу интересен концепт во полето на машинско учење претставуваат Генеративните Непријателски Мрежи (анг. Generative Adverserial Networks - GAN) каде што две подмрежи работат енда против друга. Првата мрежа, наречена "генератор", учи како да генерира лажни примероци врз основа на оригиналното множество со цел да ја излаже втората мрежа, наречена "дискриминатор", чија задача е да одреди дали примерокот кој и е прикажан е реален припаник на оригиналното податочно множество или не. Добро истрениран генератор може да се искористи за генеирање на музички секвенци. Во \cite{Yang2017,Dong2017,Dong2018} се пиркажани имплементации на GAN системи со користење на конволуциски мрежи во генераторот и дискриминаторот. Конволуциските мрежи третираат рамки од еден или повеќе такта како поединечни влезно/излезни елементи. Во вакв форма мрежите може да научат зависности само помеѓу нотите во рамки на такт, а не на подолг период, или пак помеѓу тактови. За да го решат овој проблем аврорите во Во \cite{Yang2017} користат паралелна конволуциска мрежа за условување на генераторот, која му дава на влез условена верзија од претходниот временски чекор на генераторот, со цел учење на временски зависности помеѓи два такта. Во трудовите \cite{Dong2017,Dong2018} се прикажани поамбициозни модели за генерирање на повеќе музички траки паралелно со користење на GAN систем со конволуциски генератор и дискриминатор. Секоја музичка трака има свој подмодел, кој почнува со дел за моделирање/генерирање на компонента која ја опишува песната на повисоко ниво (сублимира секвенци од тактови), која потоа служи како еден од влезовите во остатокот од системот кој што учи/генерира цели тактови. Во \cite{Dong2018} авторите додават на излез од системо додатна мрежа наменета за подобрување на реконструкцијата на тактови од реално вредносните вектори кои се излез од конволуциските мрежи, и тие се структурирани како DBN. 

This work was inspired by the legendary article by Andrej Karpathy - The Unreasonable Effectiveness of Recurrent Neural Networks \cite{AndrejKarpathy2015}. In it Karpathy shows how a neural network consisting of 2 layers of 512 LSTM cells can generalize over several datasets of textual data: Paul Graham essay, Shakespeare plays, XML and Linux C/C++ source code. The resulting model can generate new sequences that are reasonably close to the source material and can almost fool a human, and in the case of C/C++ code some of the results compile. It is a character-level language model, i.e., it learns the texts letter by letter. Our first experiment was to adapt this model to the task of music generation.


\chapter{Пристап}

Во поширокото поле на креирање на системи за генерирање на музика може да се решеаваат повеќе категории на подпроблеми, т.е. системите може да се ориентираат кон извршување на одредена карактеристична креативна задача со специфични ограничувања. Досегашните системи може да се групираат според целта врз основа на 2 критериуми:
\begin{itemize}
    \item Комплексност на музиката што се генераира, и тоа: \begin{itemize}
        \item единечна монофона мелдоија - секвенца од ноти во еден глас (ЦИТИРАЈ)
        \item единечна полифона мелодија - повеќе паралелни секвенци (делови од композиција) од ноти во гласови (контрапункт) или една секвенца од ноти или акорди (ЦИТИРАЈ)
        \item композиција од повеќе полифони траки - повеќе паралелни секвенци (делиови) од ноти или агорди (ЦИТИРАЈ)
    \end{itemize}
    \item Независност на алрогитамот за креирање, и тоа: \begin{itemize}
        \item помогната човечка композиција - алгоритамот му помага на човечки композитор при работа, нудејќи интелигентно дополнување, реаранжмани, поправки или идеји (ЦИТИРАЈ)
        \item рехармонизација/реаранжман/римејк - дополнување на композиција брз основа на еден или повеќе постоечки делови, генерирање на мелодиска придружба врз основа на секвенца од акорди (или обратно), генерирање на музичка придружба врз основа на ритамска или мелодиска линија (ЦИТИРАЈ)
        \item самостојно генерирање - генерирање на целосна музичка композиција без користење на помошна водилка (ЦИТИРАЈ)
    \end{itemize}
\end{itemize}

Во овој труд ќе го прикажам мојот обид за креирање на систем за самостојно генерирање на повеќе делна полифона музика, примарно рок музика составена од 3 дела: перкусии, гитара и бас.

\chapter{Машинско учење}

Машинско учење е област од компјутерските науки во која со примена на алгоритми и постапки за обработка на податоци врз одредено податочно множество градиме компјутерски програми за решавање реални проблеми без експлицитно програмирање на истите. Според Том Мичел од Карнеги Мелон Универзитетот: „Машинско учењер е област која се стреми да одговори на прашањето: Како може да изградиме компјутерски ситем којшто сам се подобрува со искуство, и кои се основните закони кои што го дефинираат процесот на учење на тој систем?“ Тоа е присутно насекаде, од системите за пребарување на интернет, медицински примени како детекција на рак од снимки, мапирање на човечкиот геном, синтеза на лекови; системи за препораки на филмови, музика, продажба; машински превод, гласовни асисенти и тн. Машинско учење се наоѓа на граница помеѓу компјутерски науки, статистика, математика и инженерство, меѓутоа највеќе се гледа како дел од вештачка интелигенција.

Во контекстот на машинско учење постојат два типа на пристапи: надгледувано и ненадгледувано учење. Надгледувано учење се состои од мапирање на примероци од податочно множество X кон излезна променлива Y=f(X) и најчесто решава класификациски и регресиони проблеми. Класификација претставува одредување на припадност на елементи од податочно множество во дадено множество на категории. Регресија претставува одредување на реална вредностна променлва со која опишува врската помеѓу податоците и дадена категорија. Често употребувани алгоритми се: наивен баесов класификатор, дрва за одлуки, случајни шуми, вештачки невронски мрежи, машини со носечки вектори, логистичка регресија и тн. 
Во ненадгледува учење се обидуваме да инференцираме одредена податочна структура од податоците без да внесеме во алгоритамот било какво експлицитно знаењер. Најчест проблеми који се решаваат со ненадгледувано учење се кластерирање и одредување на асоцијации помеѓу елементи. Често употребувани алгоритми се к-средини, к-медијани, анализа на главни компоненти, аутоенкодер и тн.

\subsection{Длабоко учење}

Длабоко учење е дел од машинско учење во кој се користат длабоки невронски мрежи инспирирани од физиологијата на нервните клетки и нервниот систем на човекот. Длабоко во „Длабоко учење“ доаѓа од бројот на слоеви во невронските мрежи, кој секогаш е 2 или повеќе. Предноста на ваквите алгоритми е нивната способност за самостојно екстрахирање дескриптори и атрибути од податоците, на повеќе нивоа на апстракција, со кои податоците ќе бидат соодветно опишани. Длабочината на мрежите влијае директно врз нивната експресивност. За разлика од другите типови на алгоритми за машинско учење кои што постигнуваат плато во перформансите со одредено количество на податци, длабоките невронски мрежи имаат се подобри перформанси како се зголемува податочното множество со кои ги тренираме. Единствено ограничување за скалирање на процесот на тренирање при работа со големо податочно множество се пресметковните и мемориските способности на хардверот кој се користи.
Според Џошуа Бенџио: „Алгоритмите за длабоко учење се методи за учење на податочна репрезентација со повеќе нивоа, кои се добиваат со композиција на едноставни не-лениеарни модули коишто ја трансформираат репрезентацијата на податоците од едно ниво (почнувајќи од сиров влез) во репрезентации на повисоко, поабстрактно ниво. Главниот аспект на длабоко учење е тоа што учењето на атрибутите не е специфицирано од страна на човечки учител, туку се учи од податоците со примена на општи процедури за учење.“
 
\section{Длабоки невонски мрежи}

Длабоките невронски мрежи се изградени од повеќе слоја од невронски ќелии (или јазли), од кои барем два се задолжителни, а тоа се влезниот и излезлниот слој. Влезниот слој ги претставува податоците на нервонската мрежа а излезниот слој ја врши задачата на мрежа, избор на класа ако е класификација, пресметка на регресиона вредност и тн. Помеѓу овие два слоја мрежата има еден или повеќе скриени слоеви, коишто го вршат адаптирањето на атрибутите кон податочното множество. (СЛИКА ОД ОСНОВНА НЕВРОНСКА МРЕЖА) Секоја ќелија во мрежата има барем еден влез и еден излез, поточно ќелиите од скриениот слој има повеќе влеза и излеза, ќелиите од влезниот слој обично само по еден влез а повеќе излеза, а ќелиите од излезниот слој обично имаат повеќе влеза и еден излезен слој. (СЛИКА ОД ЌЕЛИЈА) Излезот од ќелијата претставува математичка функција од влезовите модифицрани со тежински параметар (ФОРМУЛА ЗА ЌЕЛИЈА). При процесот на учење се модифицираат тежинските параметри на мрежата.
Тековно најчесто користени типови на длабоки невронски мрежи се:
\begin{itemize}
    \item Feed-Forward Neural Networks - Наједноставен тип на невронски мрежи, составени од елементарни невронски ќелии. Работат добро со податоци со многу шум и се едноставни за оддржување. Се користат често во системи за компјутерска визија и препознавање на глас како и како градбени компоненти во посложени мрежи.
    \item Convolutional Neural Networks - Слични на Feed-Forward мрежите, имаат пирамидална структура, каде што секој повисок слој е задолжен за вадење на помала апстрактна репрезентација на дел од слојот под него. Многу често се користи во компјутерска визија и обработка/класификација на слики и сигнали.
    \item Recurrent Neural Networks - Слични на Feed-Forward мрежите со тоа што секоја ќелија има сопствена меморија, т.е. има пристап до своите излези во последните N чекори, каде N е должина на меморијата на мрежата. Запомнетите излези доаѓаат на влез на ќелијата и се дел од пресметките на новиот излез. Најпопуларни варијанти се Long Short Term Memory и Gater Recurrent Unit. Најчесто се користат при работа со секвенцијални податоци, како на пример предвидување на временски серии, машински превод, препознавање на глас, препознавање на ракопис и тн.
    \item Хибридни мрежи се составени од повеќе видови на слоеви од невронски мрежи или цели подмрежи, и секој од деловите на мрежата придонесува со својата под-задача кон главната задача. Подмрежите обично немаат споделени врски помеѓу сопствените скриени слоеви и слоевите на другите подмрежи.
\end{itemize}
 
\section{Учење на секвенци}

What is sequence-to-sequence learning?
Applications are speech recognition, machine translation, image captioning and question answering.
Sequence to sequence learning:
Try to learn a mapping from one sequence to another sequence
Examples include
Machine translation (MT)
Automatic speech recognition (ASR)
Speech synthesis (TTS)
Handwriting generation

Sequence-to-sequence learning (Seq2Seq) is about training models to convert sequences from one domain (e.g. sentences in English) to sequences in another domain (e.g. the same sentences translated to French).
"the cat sat on the mat" -> [Seq2Seq model] -> "le chat etait assis sur le tapis"
This can be used for machine translation or for free-from question answering (generating a natural language answer given a natural language question) -- in general, it is applicable any time you need to generate text. There are multiple ways to handle this task, either using RNNs or using 1D convnets. Here we will focus on RNNs.

Sequence learning problems are used to better understand the different types of sequence learning. There are four basic sequence learning problems: sequence prediction, sequence generation, sequence recognition, and sequential decision making. These “problems” show how sequences are formulated. They show the patterns sequences follow and how these different sequence learning problems are related to each other.
Sequence prediction attempts to predict the next immediate element of a sequence based on all the preceding elements. Sequence generation is basically the same as sequence prediction: an attempt to piece together a sequence one by one the way it naturally occurs. Sequence recognition takes certain criteria and determines whether the sequence is legitimate. Sequential decision making or sequence generation through actions breaks down into three variations: goal-oriented, trajectory-oriented, and reinforcement-maximizing. These three variations all want to pick the action(s) or step(s) that will lead to the goal in the future.[5]
These sequence learning problems reflect hierarchical organization of plans because each element in the sequences builds on the previous elements. 

\section{Рекурентни невронски мрежи}

Рекурентните невронски мрежи се варијанта на Feed-forward мрежите со внатрешна меморија (или состојба) што ги оспособува за работа со секвенцијални податоци. кај нив излезите од тековниот временски чекор се користат како влезови при наредните временски чекори. Постојат две категории на рекурентни невронски мрежи: со бесконечен и со конечен пренос на грешката наназад. Мрежите кај кои грешката се пренесува конечен број чекори наназад преставуваат насочен ацикличен граф и истите може да се разложат (или одвиткаат) на состани feed-forward подмрежи, по една за секој временски чекор за кој се пренесува импулсот, додека мрежите кај кои преносот на грешка е бесконечен се насочен цикличен граф и не може да се разложат на составни подмрежи. Меморијата во невронските ќелии се имплементира со механизам на порта (или влез) за меморија и мрежата има контрола над мемориските порти. Постојат повеќе варијанти на рекурентни невронски мрежи како на пример: целосно рекурентни невронски мрежи, рекурзивни невронски мрежи, Long Short-Term Memory мрежи, Gated Recurrent Unit мрежи и тн. 

\subsection{Backpropagation Through Time}
Рекурентните невронски мрежи се тренираат со алгоритамот Backpropagation Through Time (накратко BPTT) - Пренос на грешка назад низ времето, со кој ги ажурираме вредностите на тежиниските параметри на ќелиите. Алгоритмот може да се сумира со следните чекори:
\begin{itemize}
    \item Приказ на влезен примерок на мрежата и пресметка на изелзите низ сите слоеви во мрежата.
    \item Споредба на добиениот излез од крајниот слој и коректниот излез и пресметка на грешка.
    \item Пресметка на изводите на грешката во однос на тежинските параметри на мрежата.
    \item Промена на тежинските параметри на мрежата со цел намалување на пресметаната грешка.
    \item Повторување.
\end{itemize}

За секвенца со должина N временски чекори, RNN работат така што ја одвиткува мрежата за секој временски чекор, и за секој има еден влезен елемент и една копија од мрежата. Грешките се пресметуваат чекор по чекор, а потоа се пресметува кумулативна грешка за секвенцата и мрежата се замотува и се извршува промената на тежинските параметри со цел намалување на пресметаната кумулативна грешка. Пресметковната комплексност на алгоритамот расте со бројот на временски чекори во секвенците што се обработуваат. 

\subsection{Truncated Backpropagation Through Time}

Поради директната зависност на пресметковната комплексност на дожините на секвенците не практично е да се тренираат RNN модели со долги секвенци. Truncated Backpropagation Through Time (накратко TBPTT) - Скратен пренос на грешка назад низ времето е апроксимативна верзија на BPTT алгоритамот со кој се решава проблемот на пресметковна комплексност. Кај него секвенцата се обработува само чекор по чекор, при што ажурирањето на тежинските параметри се врши на секои k1 временски чекори, при што грешката се пресметува за последните k2 временски чекори. Алгоритамот може да се сумира на следните чекори:
\begin{itemize}
    \item Приказ на мрежата на секвенца од k1 број временски чекори и пресметка на нивните излези.
    \item Одвиткување на мрежата и пресметка на акумулирана грешка за k2 временски чекори наназад.
    \item Завиткување на мрежата и ажурирање на тежинските параметри.
    \item Повторување.
\end{itemize}

Со параметрите k1 и k2 ги дефинираме перформансите на мрежата. Со k1 се условува колку брзо ќе се тренира мрежата т.е. колку често ќе се ажурираат нејзините тежински параметри, а k2 условува колкав ќе биде прозорецот за гледање наназад во секвенцта, т.е. колку од секвенцата може да види при секој временски чекор мрежата. Поголема вредност за k2 овозможува повеќе можност за учење на глобална структура, меѓутоа со преголемо зголемување често мрежата губи секакви можности за учење така што се нулираат градиентите на тежинските параметри.

\subsection{Експлодирачки / нулирачки градиент}

Голем проблем кај рекурерентните невронски мрежи претставуваат експлодирачкиот и нулирачкиот градиент. И двата проблеми доаѓаат од начинот на пресметка на грешка и ажурирање на тежините. Грешката се пресметува при секој временски чекор, а градиентите на грешка се мултиплицираат. Доколку се појавува често вредност поголема од 1.0, вредностите на градиентот скокаат брзо и мрежата станува нестабилна. Ако има повеќе такви градиенти еден по друг акумулираната вредност може да стане и поголема од капацитетот за целобројни вредности на машината реултирајќи во overflow и NaN вредности. Ова појава се нарекува експлодирачки градиент. Нулирачки градиент е пак спротивно кога вредностите на градиентот на грешка се премали, па тежинските параметри на одредени (или дури сите) ќелии во мрежата постануваат нула, што ефективно ги прави мртви (или неактивни). Експлодирачкиот и нулирачкиот градиент влијаат на способноста на мрежата да учи долги секвенци. Еден од начините да се намали нивното влијание е да се ограничи бројот на чекори за који се акумулира (пресметува) градиентот на грешка.

\section{Long Short-Term Memory }

Long Short-Term Memory (накратко LSTM) - Долга краткотрајна меморија, е една од пософистицираните варијанти на ќелии за рекурентни невронски мрежи, кои се обидуваат да го решат проблемот на експлодирачки/нулирачки градиент, а воедо воведува и можност за учење на произволно долги секвенци. Секоја LSTM ќелија има константна рекурентна врска, со тежински параметер константно поставен на 1.0. Ова врска и дава мемориски капацитет на ќелијата и овозможува константен пренос на градиентот на грешка, што ја штити ќелијата од нулирачки градиент. 
LSTM ќелиите има 3 карактеристични порти кои го управуваат нејзиното работење: порта за заборавање, порта за модификација и порта за излез. Во одредени ситации е корисно ќелијата да го "заборави" тоа што го има во својата меморија, како на пример кога содржи ирелевантни или застарени податоци. За таа цел LSTM ќелиите имаа влез за заборавање, кој што прима вредност од 0 или 1. Содржината на ќелијата се множи со таа вредност, па така кога е 0 ќелијата практично заборава се, а кога е 1 помни се. Нема множност за парцијална модификација на вредноста. Наспроти ова, во ситуации кога содржината на ќелијата треба да биде заштитена од модификација во одреден временски чекор, се користи порта за модификација. Со неа може да се заштити содржината на ќелијата повеќе временски чекори, овозможувајќи користење на информации во тековниот временски чекор од пред произволем број временски чекори. Последната порта, портата за излез овозможува игнорирање на излезот од ќелијата. Ова е корисно во ситуации каде повеќе ќелии би имале релевантна информација, но некои од нив имаа хипотетички порелевантна информација, па тие што не се толку релевантни излезот им го игнорира мрежата со користење на портата за излез.

(ДИЈАГРАМ ОД ЛСТМ ЌЕЛИЈА)

Овие карактеристи ги прават мрежите изградени од LSTM ќелии способни за работа со доста долги секвенци, со должини поголеми и од 1000 елементи, како и со работа со секвенци со произволна должина, со секвенци во кои има доста шум, секвенци кои што не може едноставно да се компресираат и тн.

\section{Вградување на зборови во латентен простор}

При работа со податочни множества каде што има голем број на уникатни влези елементи, категоричната репрезентација на влезните елементи, т.н. 1-hot вектор (бинарен вектор со должина еднаква на бројот на уникатни влезни елементи, каде што само една позиција има вредност 1 а сите останати 0, а тоа е позицијата на влезниот елемент во подреденото множество на уникатни влезни елементи) има драстично влијание врз перформансите на моделите за машинско учење. Таквите вектори се екстремно ретки и причинуваат пресметко проблеми со денешните алатки за машинско учење бидејќи ниедна нема ефикасна репрезентација на ретки вектори и матрици. 
Едно практично решеније на овој проблем претставува вградувањето во латентен простор. Елементите од оригиналното множество ги претставуваме со многу пократок вектор со фиксна должина, Овој вектор се состои само од реални вредности, и претставува компресирана и дистрибуирана репрезентација на оригиналниот влезен вектор. Овој вектор и процесот на вградување може да се изведе со невронски мрежи, и според начинот на кој ќе се тренира мрежата во него може да се врадат различни семантички информации за влезното множество. Големината на векторот на вградување обично се движи помеѓи десетици и стотици елементи.
Вградувањето може да се тренира одделно или како дел од главниот модел за машинско учење за кој е наменето. Одделното тренирање е добро доколку има потреба од реискористување на вградувањето за други модели, бидејќи може да се зачува како компонента. Од друга страна ако не се планира користење надвор од моделот, тренирањето како дел од моделот е поедноставно и попрактично.

Наједноставна имплементација на вгравуањето во латентен простор е кога се тренира како дел од мрежата. Тоа се постигнува со користење на еден feed-forward слој, чија големина е параметер на севкупниот модел, и обично е во ранг на стотици елементи. Векторот се иницијализира со мали случајни броеви, а слојот се тренира со Backpropagation алгоритамот.

Word2Vec, претставен во \cite{Mikolov2013}, е пософистициран модел за вградување на зборови во латентен простор. Со користењер на статистички методи за анализа на колокација на зборови во моделот додаваат информации за поврзаноста помеѓу зборовите според тоа колку често се појавуваат заедно. Имаат две варијанти на моделот: bag-of-words и skip-gram. Првата варијанта ги учи вградувањата така што го предвидува тековниот збор врз основа на контекстот, додека другиот модел ги предвидува ближните зборови врз основа на тековниот. 
Chord2Vec \cite{Madjiheurem2016} моделот претставува имплементација на skipgram моделот од Word2Vec со Neural Autoregressive Distribution Estimator (накратко NADE). Наменет е да ги научи појавувањата на нотите во контекст на акорд, со цел генерирање на акорди како основен дел од музичка композиција. 

\section{Gibbs sampling / Гибсово семплирање}

Гибсово семплирање е техника за генерирање на примероци од мултиваријабилна дистрибуција каде што ни е познат само дел од условната дистрибуција. Техниката е Монте Карло Марков Ланец и се базира на претпоставката дека може да ја пресметаме условни дистрибуции на една од променливите условени од сите други променливи, и дека можеме да вадиме примероци од добиените дистрибуции. Гибсово семплирање е доста корисно за вадење на примероци од непозната дистрибуција. Пример имплементација е Гибосово семплирање со случајно секнирање дадена со:
1.Initialize x(t)=(x(t)1,...,x(t)k)for t=0
2. For t=0,1,...
    1. Pick index i uniformly at random from 1,...,k
    2. Draw a sample a∼p(x′i∣x(t)−i) where x(t)−i is the set of all variables in x(t) except for the ith variable.
    3. Let x(t+1)=(x(t)1,x(t)2,...,x(t)i−1,a,x(t)i+1,...,x(t)k)

Искористен е во следните трудови: \cite{Hadjeres2016} (DOVRSI). Според \cite{Hadjeres2016} техниката е подогна во контекстот на музика само доколку работиме со категорични податоци (1-hot вектори или симобили), а не со пиано ленти, бидејќи не може да се справи добро со симултано менување на повеќе променливи.


\chapter{}
Monophonic music composition is the art of creating a single melodic line with no accompaniment. To compose a melody a human composer uses his/her creativity and musical knowledge. In our model composer function C generates a melodic line based on knowledge represented by cumulative frequency distribution matrix CFM.

\chapter{Евалуација}

Which is better?

An interesting experiment that was performed in 2016 by the Sony Computer Science Laboratories in Paris tested people's ability to identify AI generated music: 1,600 people were asked to listen to two distinct harmonies of the same melody – one by Bach and one by an AI called “DeepBach’”. The results showed that more than half of the listeners attributed the DeepBach-generated harmonies to Bach himself, while 75percent  of listeners were able to identify Bach’s music. It’s worth mentioning that a fourth of the testers were professional musicians or music students.
While it’s becoming harder and harder to distinguish between human and AI generated music, the question of which of them is better will probably remain open forever. After all, when it comes to music, it all comes down topersonal taste. One advantage that AI does have is the ability to analyze people's personal taste in order to adjust songs so they are more suited to their tastes and by this reduce the risk of failure. Would this ability prevail over the human "creative spark”? only time will tell.

\cite{Hadjeres2016} Discrimination Test: “Bach or Computer” experiment
Subjects were presented series of only one musical extract together with the binary choice “Bach” or “Computer”. Fig. 5 shows howthe votes are distributed depending on the level of musical expertise of the subjects for each model. For this experiment, 1272 people took this test, 261 with musical expertise 1, 646 with musical expertise 2 and 365 with musical expertise 3.
Subjects were asked to give information about their musical expertise. They could choose what category fits them best between:
1. I seldom listen to classical music
2. Music lover or musician
3. Student in music composition or professional musi- cian.
Interactive composition 4.1. Description
We developed a plugin on top of the MuseScore music editor allowing a user to call DeepBach on any rectangu- lar region. Even if the interface is minimal (see Fig.7), the possibilities are numerous: we can generate a chorale from scratch, reharmonize a melody and regenerate a given chord, bar or part. We believe that this interplay between a user and the system can boost creativity and can interest a wide range of audience.

\cite{Liang2017} 
To measure BachBot’s success in this task, we devel- oped a publicly accessible musical discrimination test at bachbot.com. Unlike prior studies which leverage paid services like Amazon MTurk for human feedback [35], we offered no such incentive and promoted the study only through social media. Participants were first surveyed for their age group and prior music experience (fig. 3a). Next, they are presented five discrimination tasks which presented two audio tracks (an original Bach composition and a synthetic composition by BachBot) and ask them to identify the Bach original. Each audio track contains an entire composition from start to end. The music score for the audio was not provided. Participants were granted an unlimited amount of time and allowed to replay each track an arbitrary number of times. Participants could only see the next question after submit- ting the current one and were not allowed to modify their responses after submitting. The five questions comprised of three harmonizations (S/A/T/B, one AT, one ATB), and two original compositions. To construct the questions, harmonizations were paired along with the original Bach chorales the fixed parts were taken from. No such direct comparison is possible for the SATB case, so these synthetic compositions were paired with a randomly selected Bach chorale in a some- what different comparative listening task. Harmonizations were synthesized by extracting part(s) from a randomly se- lected Bach chorale and filling in the remaining parts of the composition using the method previously described in sec- tion 2.4. Original compositions (questions labelled SATB) were generated by providing a START symbol followed by ancestral sampling as previously described in section 2.3 until an END symbol is reached. The final audio provided in the questions were obtained by rendering the composi- tions using the Piano instrument from the Fluid R3 GM SoundFont.
We only considered the first response per IP address of participants who had played both choices in every question at least once and completed all five questions. This totaled 2336 participants at the time of writing, making our study one of the largest subjective listening evaluation of an au- tomatic composition system to date.
An informal analysis sug- gests that while some neurons are ambiguous to interpreta- tion, other neurons correlate significantly with recognized music-theoretic objects, particularly chords (see fig. 4). To our knowledge, this is the first reported evidence for an LSTM optimized for automatic composition learning music-theoretic concepts without explicit prior informa- tion. This invites a follow-up study testing the statistical significance of these observations.

\cite{MidiNet} To evaluate the aesthetic quality of the generation result, a user study that involves human listeners is needed. We conducted a study with 21 participants. Ten of them un- derstand basic music theory and have the experience of be- ing an amateur musician, so we considered them as people with musical backgrounds, or professionals for short. We compared MidiNet with three MelodyRNN models pre-trained and released by Google Magenta: the basic RNN, the lookback RNN, and the attention RNN [33]. We randomly picked 100 priming melodies from the training data 7 and asked the models create melodies of eight bars by following these primers. We considered two variants of MidiNet in the user study: model 1 (Section 4.2.1) for fair comparison with MelodyRNN, and model 2 (Section 4.2.2) for probing the effects of using chords. Although the result of model 2 was generated by additionally following the chords, we did not playback the chord channel in the user study. We randomly selected the generation result of three out of the 100 priming melodies for each participant to listen to, leading to three sets of music. To avoid bias, we ran- domly shuffled the generation result by the five considered models, such that in each set the ordering of the five mod- els is different. The participants were asked to stay in a quiet room separately and used a headphone for music lis- tening through the Internet, one set at a time. We told them that some of the music “might be” real, and some might be generated by machine, although all of them were actu- ally automatically generated. They were asked to rate the generated melodies in terms of the following three metrics: how pleasing, how real, and how interesting, from 1 (low) to 5 (high) in a five-point Likert scale.

\section{Rangiranje}

\cite{GarciaSalas2011}

 \cite{GarciaSalas2011} Во трудот е опишана и евалуација на резултатите во стил на Турингов тест, на 30 учесници од различна возраст и познавање на музика, но поголем дел од ИТ индустрија, им биле пуштени 10 песни, 5 генеирани од човек, а 5 од алгоритмот, кои ги рангирале по тоа колку им се допаѓаат. Две од генерираните песни биле рангирани на позиција 3 и 4. 


\chapter{Податоци}

\section{Податочно множество}

\section{Податочна репрезентација}

Изворно податочно множество, влез на системот, излез од системот. 

\cite{Tikhonov2017} For each note we were building a note embedding that corresponded to the pitch of the note, an octave embedding that corresponded to the octave of the note and a delay embedding that corresponded to the length of the note. We were using this three embeddings and meta-information of a given MIDI track to build a concatenated note representation that was used as an input for training throughout this paper.

\subsection{Репрезентација на времето}
4.4.1 Global vs Time Slice
The representation of time is fundamental for musical processes. There is a first decision about the temporal scope of the representation (and its relation to the temporal nature of the architecture used):
• global – In this first case, there is no notion of temporal sequence and no explicit notion of time. The granularity of processing by the deep network architecture is the represen-
tation as a whole. The architecture used is not recurrent (typically a feedforward archi- tecture or an autoencoder). Examples are the MiniBach system (see Section 7.1.1.1) and the DeepHear system (see Section 7.1.3.1).
• time step (or time slice) – In this second case, the most frequent one, the atomic temporal granularity of the input (training input or generation input) is a local temporal slice
of the musical content, corresponding to a specific temporal moment (time step). The granularity of processing by the deep network architecture is a time step. Note that the time slice is usually set to the shortest note duration (see Section 4.4.3), but it may be set larger, e.g., to a measure in the system discussed in [106].
• note step – This third case, rare, is proposed byWalder in [113]. In this approach, there is no fixed time step. The granularity of processing by the deep network architecture is
a note. See [113] for more details. A corollary of this design decision is that in the global case, the representation of a
musical data used as a a training input and as a generation input needs to have a fixed size (the number of time steps), whereas in the time step and note step cases, the sequence size is variable: actual lengths of the training input, the generation input and the generated output may be different.

\subsection{Краеви на нотите}
4.4.2 Note Ending
Another important issue is about the note ending, i.e. how is (or is not) represented the end of a note. In the MIDI representation format, the end of a note is explicitly stated (via a Note Off event13). In the piano roll14 notation shown in Section 4.3.2, there is no explicit representation of the ending of a note and, as a result, one cannot distinguish between two
repeating quarter notes ˇ “ ˇ “ and a half note ˘ “. In [21], Eck and Schmidhuber mention two strategies to address this limitation:
• a first strategy (and the most common one) is to divide by 2 the size of the time step (time slice)15 and always mark note endings with a special tag, e.g., 0. The advantage is
that one does not need to change input and target data structures;
• an alternative strategy is to have a special computing unit(s) in the network to indicate the beginning of a note. This method is employed by Todd in [106].

\subsection{Резолуција}
4.4.3 Time Quantization
Some global time quantization, i.e. the definition of the value of the time step is needed to temporally interpret the representation. Eck and Schmidhuber [21] mentions two alternative strategies:
• most commonly, the time step is set to the smallest duration of a note in the corpus
(training examples/dataset), e.g., a sixteenth note ˇ “) . One immediate consequence of this “leveling down” is the number of processing steps necessary independently of the duration of actual notes;
• an alternative strategy, interesting to be noted, was devised by Mozer in the CONCERT system [77] (see Section 7.3.1.1), who used a distributed encoding of duration that al-
lowed him to process a note of any duration in a single network processing time step. By representing in a single time step a note rather than a slice of time, the number of time steps to be bridged by the network in learning global structure is greatly reduced. The approach ofWalder for a note granularity of processing (see Section 4.4.1) is analog. In this strategy, there is no uniform discretization of time (time slice) and no need for.

4.4.3 Time Quantization
Some global time quantization, i.e. the definition of the value of the time step is needed to temporally interpret the representation. Eck and Schmidhuber [21] mentions two alternative strategies:
• most commonly, the time step is set to the smallest duration of a note in the corpus
(training examples/dataset), e.g., a sixteenth note ˇ “) . One immediate consequence of this “leveling down” is the number of processing steps necessary independently of the duration of actual notes;
• an alternative strategy, interesting to be noted, was devised by Mozer in the CONCERT system [77] (see Section 7.3.1.1), who used a distributed encoding of duration that al-
lowed him to process a note of any duration in a single network processing time step. By representing in a single time step a note rather than a slice of time, the number of time steps to be bridged by the network in learning global structure is greatly reduced. The approach ofWalder for a note granularity of processing (see Section 4.4.1) is analog. In this strategy, there is no uniform discretization of time (time slice) and no need for.

\subsection{Аудио сигнал}

\subsection{MIDI}

MIDI (Musical Instrument Digital Interface) is a technical standard that describes a proto- col, a digital interface and connectors for interoperability between various electronic musi- cal instruments, software and devices [73]. MIDI carries event messages that specify note information (such as pitch and velocity) as well as control signals for parameters (such as volume, vibrato and clock signals). There are five types of messages and here we only consider the Channel Voice type, which transmits real-time performance data over a single channel. Two important (for our concerns) messages are:
• Note on – To indicate that a note is (or has to be) played. It contains a status information (what channel number is concerned, specified by an integer within [0 15] and two
data values: a MIDI note number (the note’s pitch, an integer within [0 127]) and a velocity (that indicates how loud the note is played3, an integer within [0 127]). An example is <Note on, 0, 60, 50> which interprets as: “on channel 1, start playing a middle C with velocity 50”.
• Note off – To indicate that a note ends. In that situation, velocity indicates how fast the note is released. An example is <Note off, 0, 60, 20> which interprets as: “on
channel 1, stop playing a middle C with velocity 20”.
Each note event is actually embedded into a track chunk, a data structure containing a delta-time value which specifies the timing information and the event itself. A delta-time value represents the time position, as an absolute value, of the event and could represent:
• a metrical time – It represents the number of ticks from the beginning. A reference, named the division and defined in the file header, specifies how many ticks per quarter
note ˇ “, or a time-code-based time – Not detailed here. An example of extract from a MIDI file (turnt into readable ascii) and its corresponding
score are shown at Figures 4.2 and 4.3. The division has been set to 384, i.e. 384 ticks per quarter note ˇ “, which corresponds to 96 ticks for an eighteenth note ˇ “) .
In Huang and Hu claim that one drawback of encoding MIDI messages directly
is that it does not effectively preserve the notion of multiple notes being played at once through the use of multiple tracks. Since they concatenate tracks end-to-end, they posit that it will be difficult for such a model to learn that multiple notes in the same position across different tracks can really be played at the same time.

\subsection{Текст}

ABC \cite{Sturm2015}
ABC notation is a shorthand form of musical notation. In basic form it uses the letters A through G to represent the given notes, with other elements used to place added value on these - sharp, flat, the length of the note, key, ornamentation. Later, with computers becoming a major means of communication, others saw the possibilities of using this form of notation as an ASCII code that could facilitate the sharing of music online, also adding a new and simple language for software developers. In this later form it remains a language for notating music using the ASCII character set. The earlier ABC notation was built on, standardized and changed to better fit the keyboard and an ASCII character set by Chris Walshaw, with the help and input of others. Although now re-packaged in this form, the original ease of writing and reading, for memory jogs and for sharing tunes with others on a scrap of paper or a beer coaster remains, a simple and accessible form of music notation, not unlike others, such as tablature and solfège. Originally designed for use with folk and traditional tunes of Western European origin, e.g., English, Irish, Scottish, which are typically single-voice melodies that can be written on a single staff in standard notation, the work of Chris Walshaw and others has opened this up with an increased list of characters and headers in a syntax that can also support metadata for each tune.[1]

ABC notation being ASCII-based, any text editor can be used to edit the music. Even so, there are now many ABC notation software packages available that offer a wide variety of features, including the ability to read and process ABC notation into MIDI files and as standard "dotted" notation. Such software is readily available for most computer systems, including Microsoft Windows, Unix/Linux, Macintosh, Palm OS, and web-based.[2]

Later third-party software packages have provided direct output, bypassing the TeX typesetter,[3] and have extended the syntax to support lyrics aligned with notes,[4] multi-voice and multi-staff notation,[5] tablature,[6] and MIDI.[7]


Chord tabs

Chrods cite chord2vec

A melody can be encoded in a textual representation and processed as a text. A significant example is the ABC notation [115], a de facto standard for folk and traditional music4. See at Figures 4.6 and 4.7 the original score and its associated ABC notation of a music named “A Cup of Tea”, from the repository and discussion platform The Session [56]. The first 6 lines are the header and represent metadata (e.g., T: title of the music, M:
meter (it is actually the time signature), L: default length, K: key. . . ). It is followed by the main text representing the melody. We illustrate below some basic principles of the encoding rules (please refer to [115] for the details):
• the pitch class5 of a note is encoded as the letter corresponding to its english notation (e.g., A for A or La);
• its pitch is encoded as following: A corresponds to A46, a to an A one octave up and a’ to an A two octaves up;
• the duration of a note is encoded as following: if default length is marked as 1/8 (i.e. an eighth note7
ˇ “( – the case for this example), a corresponds to an eighth note ˇ “( , a/2 to a sixteenth note ˇ “) and a2 to a quarter note ˇ “;
• measures (also named bars)8 are separated by | (bars). Note that the ABC notation can only represent monodic melodies. This representation
is for instance used by Sturm in [97] (see Section 7.3.1.2). 4.3.4
A representation of a chord could be extensional, enumerating the notes composing it, or intensional, specifying the pitch class of its root note (e.g., C, A. . . ) and its type (e.g., major, minor, dominant seventh. . . ), usually using an abbreviated jazz notation, e.g., C, D-, E7. . . 9. In most cases, the abbreviated notation is chosen, as in Jazz and popular music. In summary, a chord is usually represented by a pair < pitchclass,type >, where pitch
class ∈ {A, A?10, B, . . . , G, G?} and the set of possible types is predefined (e.g., {+, -, 7, -7, +, -7(?5), 11, ?13(?9). . .}). Note that the way, standard in Jazz, to indicate a note other than the root (of the chord) as to be played by the bass (e.g., A-7/E11) is an additional issue most of time not considered in music generation.

An interesting alternative representation of chords, named Chord2Vec (inspired by the
Word2Vec model for natural language [70]), has been recently proposed in [68]12. Rather than thinking of chords (vertically) as vectors, they represent chords (horizontally) as se- quences of constituent notes. More precisely: 1) a chord is represented as an (arbitrary length) ordered sequence of notes and 2) chords are separated by a special symbol (as for sentence markers in natural language processing). When using this representation for predicting neighboring chords, a specific compound architecture is used, named RNN Encoder-Decoder, offering a very accurate model (see Section 7.3.4.1). Note that a somehow similar model has been used for polyphonic music generation in
the BachBot system [66] (analyzed in Section 7.3.1.3). In this model, for each time step, the various notes are represented as a sequence and a special delimiter symbol (|||) indicates
the next time frame (with constant time step of an eighth note ˇ “( ). Notes are ordered, in a descending pitch (soprano voice being the first one). Each note is encoded as its MIDI pitch
value and a boolean indicating if it is tied to a note at the same pitch from previous frame. An example is shown at Figure 4.8, encoding two successive chords (the first having the duration of a quarter note) and the second one possessing a fermata (noted as (.)).

\subsection{Пиално лента}

The piano roll representation of a melody (monodic or polyphonic) is inspired from au- tomated pianos (see Figure 4.4). This was a continuous roll of paper with perforations (holes) punched into it. Each perforation represents a note control information, to trigger a given note. The length of the perforation corresponds to the duration of a note. On the other dimension, the localization of a perforation corresponds to its pitch. An example of a modern piano roll representation (for digital music systems) is shown
at Figure 4.5. The x axis represents time and the y axis the pitch. In that example, two voices are encoded. The piano roll is one of the most frequent representations used, although it has some limitations. An important one, comparing to MIDI representation, is that the information of the note off does not exist. As a result, there is no way to distinguish between a long note and two short notes (see Section 4.4.2). The experiment conducted by Huang and Hu [47] is interesting in that they compare using MIDI and piano roll formats. See also the publication byWalder entitled “Modelling Symbolic Music: Beyond the Piano Roll” [113]

\subsection{Distributed note representation / circle of fifths}

Mozer [29] builds RNN to model and generate melody using a distributed
approach to music encoding. These systems generate output at the note level rather than at uniform time steps. Each pitch is encoded based on its fundamen- tal frequency, chromatic class, and position in the circle of fifths. Note duration is encoded using a similar approach. Chordal accompaniment is encoded based on the pitches present. Some input units denote time signature, key, and down-
beats. Mozer’s

\cite{Biles1994} They only allow for 14 pitches in the melody, but those are релатив, their absolute values are chose according to a mapped chrod. A chord map is created for each half measure. Each map is an array of 14 MIDI pitches. A chord is mapped to a scale strictly vertically. After a scale is selected, it is extended to 14 tones, beginning at or above middle C. Interesting representation.

\section{Предпроцесирање, трансформации и филтрирање}

\cite{Sturm2016} We create data for training our folk-rnn model in the following way. We
remove title fields and ornaments. We remove all transcriptions that have fewer than 7 measures when considering repetitions (to remove contributions that are not complete transcriptions, but transcriptions of suggested endings, variations, etc.). We remove all transcriptions that have more than one meter or key.11 We transpose all remaining transcriptions (23,636) to a key with root C.
We impose a transcription token vocabulary — each token consists of one or more characters — for the following seven types (with examples in parens): meter (“M:3/4”), key (“K:Cmaj”), measure (“:|” and “|1”), pitch (“C” and “c’”),
grouping (“(3”), duration (“2” and “/2”), and transcription (“<s>” and “<\ s>”). 
Our dataset has 4,056,459 tokens, of which 2,816,498 are pitch, 602,673 are du- ration, and 520,290 are measure. A majority of the 23,636 transcriptions consists of 150 tokens or fewer; and 75percent have no more than 190. There are 137 unique tokens, each of which becomes a vocabulary element for our folk-rnn model.

\cite{Yang2017} 
For simplicity, we filtered out MIDI tabs that contain chords other than the 24 basic chord triads (12 major and 12 minor chords). Next, we segmented the remaining tabs every 8 bars, and then pre-processed the melody channel and the chord channel separately, as described below. For melodies, we fixed the smallest note unit to be the sixteenth note, makingw = 16. Specifically, we prolonged notes which have a pause note after them. If the first note of a bar is a pause, we extended the second note to have it played while the bar begins. There are other exceptions such as triplets and shorter notes (e.g. 32nd notes), but we chose to exclude them in this implementation. More- over, for simplicity, we shifted all the melodies into two oc- taves, from C4 to B5, and neglected the velocity of the note events. Although our melodies would use only 24 possible notes after these preprocessing steps, we considered all the 128 MIDI notes (i.e. from C0 to G10) in our symbolic representation. In doing so, we can detect model collaps- ing [12] more easily, by checking whether the model gen- erates notes outside these octaves. As there are no pauses in our data after preprocessing, we do not need a dimension for silence. Therefore, h = 128. For chords, instead of using a 24-dimensional one-hot vector, we found it more efficient to use a chord representa- tion that has only 13 dimensions— the first 12 dimensions for marking the key, and the last for the chord type (i.e. major or minor), as illustrated in Table 2. We pruned the chords such that there is only one chord per bar. After these preprocessing steps, we were left with 526 MIDI tabs (i.e. 4,208 bars). 5 For data augmentation, we circularly shifted the melodies and chords to any of the 12 keys in equal temperament, leading to a final dataset of 50,496 bars of melody and chord pairs for training.

\cite{Tikhonov2017}  1. Spliting the midi tracks and filtering only the desired ones by heuristic. 2. Removed strenght/velocity of the note being played, to focus on the melodic pattern determined by the pitches and temporal parameters of the notes and pauses in between and not performance nuances. 3. In order to make the learning state space denser we have centered the pitches throughout the dataset transposing median pitch of every track to the 4th octave. 4. We also normalized the pauses throughout the dataset in the following manner. For each track we have calculated a median pause. It is only to be expected that absolute majority of the pauses in the track were equal to the median pause multiplied with a rational coefficient (naturally 1/2 and 3/2 were especially popular in the majority of the tracks). We counted all possible pauses in every track and left only the tracks that had 11 different values of the pauses or less (the median + most popular pauses on each side of it). The tracks with higher variety of pauses were not included in the final dataset.
5. Finally to make the input diverse enough we have filtered the tracks with exceedingly small entropy.


\subsection{Транспозиција}

A common technique in machine learning is to generate synthetic data as a way to artifi- cially augment the size of the dataset (the number of training examples) in order to improve the learning. In the musical domain, a natural and easy way is transposition, i.e. to trans- pose all examples in all keys21. In addition to artificially augment the dataset, this provides a key (tonality) invariance of all examples and thus makes the examples more generic. This also reduces sparsity in the training data. This transposition technique is for instance used in [61], described in Section 7.7.1.1. An opposed approach is to transpose (align) all ex- amples into a single common key. This has been advocated by [7] to facilitate learning (see Section 7.3.2.1).
4.4.9

\cite{Bretan2016} 3.1 Design of a Musical DBN Autoencoder
In order to analyze and reconstruct a melody we trained a deep autoencoder to encode and decode a single measure of music. This means that our unit (in this scenario) is one measure of music. From the dataset there are roughly 170,000 unique measures. Of these, there are roughly 20,000 unique rhythms seen in the measures. We augment the dataset by manipulating pitches through linear shifts (transpositions) and alterations of the intervals between notes resulting in roughly 80 million unique measures. We augment the dataset by manipulating pitches through linear shifts (transpositions) and alterations
of the intervals between notes. We alter the intervals using two methods: 1) adding a constant value to the original intervals and 2) multiplying a constant value to the intervals. Many different constant values are used and the resulting pitches from the new interval values are superimposed on to the measure’s original rhythms. The new unit is added to the dataset. We restrict the library to measures with pitches that fall into a five octave range (midi notes 36-92). Each measure is transposed up and down a half step so that all instances within the pitch range are covered. The only manipulation performed on the duration values of notes within a measure is the temporal compression of two consecutive measures into a single measure. This “double time" representation effectively increases the number of measures, while leaving the inherent rhythmic structure in tact. After all of this manipulation and augmentation there are roughly 80 million unique measures. We use 60% for training and 40% for testing our autoencoder. The first step in the process is feature extraction and creating a vector representation of the unit. Unit
selection allows for a lossy representation of the events within a measure. As long as it is possible to rank the units it is not necessary to be able to recreate the exact sequence of notes with the autoencoder. Therefore, we can represent each measure using a bag-of-words (BOW) like feature vector. Our features include:
1. counts of note tuples <pitch1, duration1> 2. counts of pitches <pitch1> 3. counts of durations <duration1> 4. counts of pitch class <class1> 5. counts of class and rhythm tuples <class1, duration1> 6. counts of pitch bigrams <pitch1, pitch2>

\subsection{Филтрирање}


\chapter{Tools}

\section{Keras}

\section{Music21}

\section{pypianoroll}

\chapter{Студија на случај}

\section{Податочно множество}

Најдостапен и најлесен за комјутерска обработка извор на симболична музука претставуваат МИДИ датотеките. Во иницијалните фази на изработка користев мало податочно множество коешто го изградив од GuitarPro датотеки рачно избрани од http://ultimate-guitar.com. Датотеките преставуваат кориснички генерирана репрезентација на музиката, примарно наменети за учење. Бидејќи системот за репродукција на звук за GuitarPro датотеките е базиран на MIDI стандардот, можев лесно да ги конвертирам во MIDI датотеки. Финалниот чекор за подготовка на податоците е трансформација во пиано лента репрезентација. За жал процесот резултираше во неквалитетна конверзија, песните во финалната форма има многу аномалии, неправилности и изгубена смисла на одредени елементи. Се појавија многу тонови со времетраење од 0 рамки, како и тонови со времетраење од десетици секунди. Исто така се појавија истровремено свирење на 10 и повеќе тонови на гитара, што е невозможно со стандардна гитара. Добар дел од проблемите следат од тоа што датотеките се кориснички генерирани што не гарантира квалитет, како и од алатките за конверзија. Затоа одлучива да ја напуштам оригиналната замисла и да користам готово податочно множество.

\subsection{Лахк (Lahk) MIDI}

Лахк MIDI податочното множество се состои од 176.581 уникатни MIDI датотеки, соберени од страна Рафел за целите на неговоит труд \cite{Raffel2016} во кој покажува систем за пребарување и споредување на секвенци, или исечоци, од MIDI датотеки. Дел од овие множеството, наречен LMD-Matched, се состои од 45.129 датотеки спарени со соодвенти метаподатоци од датабазата MillionSongs, што овозможува пребарување, групирање и селекција по одредени критериуми како жанр, автор, стил, темпо и сл. 
Врз основа на LMD-Matched податочното множество, Донг за потребите на трудот \cite{Dong2017} го имат конвертирано целото податочно множество во пиано лентал. На веб страната на која е прикажан нивниот труд се достпни повеќе верзии од множеството:

\begin{itemize}
    \item LPD-Cleansed - Претставува прочистена верзија на податочното множество според следните критериуми: отстранети песни кои не се со 4/4 ритам, отстранети песни со повеќе од една промена на ритам, остранети песни каде што првиот такт не почнува од нулти момент, задржани песните кои што со наголема сигурност се спарени со ставка од MillionSongs датабазата.
    \item LPD-5 - Сите можни инстанци на инструменти во MIDI датотеките се групирани во следните 5 категории: тапани, пиано, гитара, бас и жичана секција; според MIDI програмскиот број на инструментот. Неголем дел од инструментите кои не припаѓаат на ниту една од овие категории се групирани во жичаната секција, со исклучок на синтисајзер, перкусии и звучни ефекти.
    \item LPD-17 - Слично на претходното множество со тоа што инструментите се групирани во 17 категории: тапани, пиано, хроматски перкусии, оргуља, гитара, бас, жичана секција, ансамбл, метални дувачки инструменти, дрвени дувачки, писка, главен синтисајзер, придружба синтисајзер, етнички инструменти, перкусии и звучни ефекти.
\end{itemize}

LPD-5 податочното множество се покажа како одлична појдовна точка за изградба на помало податочно множество за експериментите, бидејќи содржи песни со константен 4/4 ритам. Меѓутоа не е доволно добро за употреба без модификација. Не сите песни ги имаат сите инструменти, а некои песни имаат повеќе инструменти групирани во една трака, така да потребна е додатна обработка и селекција за да се добие квалитетно податочно множество.

\section{Податочна репрезентација}

Песните во LPD-5 податочното множество се во пиано лента репрезентација, каде што времето е поделено така што една рамка од лентата претставува 1/24 од еден такт. Една рамка се содржи од 128 целобројни вредности, по една за секоја од можните ноти или звуци опишани со MIDI стандардот, при што вредноста го опипува интензитетот со кој се присутен звукот. Ваквиот вектор не е адекватен за учење на секвенци, бидејќи преставува решавање на 128 регресионони проблеми во паралела. Затоа првиот чекор во прилагодување на векторот претставува бинаризација, т.е. во секоја рамка секоја ненулта вредност се заменува со единица. Во обратна насока, при дебинаризација на векторот, единиците ги заменувам со рачно одредена вредност за интензитет, 2/3 од максималната вреднос. На овој начин се губи експресивност и нуанса, меѓутоа драстично се олеснува проблемот на учење на секвенци. 
По иницијални експерименти каде што тренирав модел да учи секвенци од тн. "multi-hot" вектори (бинарни вектори каде што повеќе вредности може да бидат активни истовремено), како што е бинаризираната варијанта на пиано ленти, дојдов до заклучок дека ваквите секвенци претставуваат тежок проблем за учење за моделите коишто сакав да ги искористам. Учење на 128 паралелни проблеми резултираше во многу ретки активации на излезниот слој, а во рамките кадешто се појавија повеќе активации, комбинациите на ноти често беа бесислени. Поради тоа одлучив да изградам лексикон од сите можни комбинации на ноти, и да ги користам елементите од лексиконот како влезе во моделот за учење. Трансформацијата ја извршив така што 128 елементниот вектор го сметам како 128 битна бинарна репрезентација на цел број. Лексиконот го изградив од ваквите целобројни репрезентации со додатни симобили за почеток и крај на песна/секвенца. Лексиконот потоа го индексирав и секој елемент доаѓа на влез на моделот во "one-hot" или 1-n бинарен вектор, во кој што сите вредности се нула, само вредноста со ист индекс како елементот од лексиконот е единица.

\section{Селекција на песни}

Датотеките од податочното множество содржат 5 траки кои ги преставуваат инструментите: тапани, пиано, гитара, бас и жичана секција. Меѓутоа не сите датотеки имаат податоци во сите траки, т.е. не е извршена претходно филтрирање на песните така што сите песни да ги имаат сите инструменти. Додатно бидејќи во жичана секција се групирана многу инструменти, што често може да доведе и до групирање на повеќе траки од изворната датотека во една, одлучив да ги филтрирам сите датотеки што содржат податоци на таа трака. Додатно голем број на песни не содржат пиано трака, а бидејки фокусот ми беше на рок песни коишто најчесто немаат пиано делови, ги исфилтрирав и пените што содржат пиано. Останатите песни ги филтрирав така да пиано лентите за траките тапани, гитара и бас гитара се целосно исполнети. Од добиеното подмножество со случајна селекција избрав 500 песни, од коишто поголем дел природно се погодија од рок, поп-рок и метал жанр. Од ова подмножество креирав MIDI датотеки со користење на pypianoroll библиотеката. Потоа со рачна инспекција на песните една по една избрав (ФИНАЛНА БРОЈКА НА ПЕСНИ) според субјективна процена за квалитетот на добиената датотека, познавање на песната, жанровска припадност и релативна едноставност на песната.

\section{Транскрипција на песните}

За збогатување на податочното множество и гарантирање на транслациона инваријанса на мелодиските линии искорив постапка на музичка транскрипција. Прво ги одредив најнискиот и највисокиот тон присутен во избраното податочно множество. Потоа за секоја од песните извришив транскрипција надолу за толку полутонови колку што има од најнискиот тон во податочното множество и најнискиот тон во самата песна, и нагоре за толку полутонови колку што има помеѓу највисокиот тон во податочното множество и највисокиот тон во поесната. Ваквата стратегија резултира во разлилен број на транскрипција по песна, зависно од колку голем е тоналниот опсег на песната, што значи некои песни се поприсутни во резултантното транскрибирано податочно множество, а некои помалку присутни; но и во најголем можен број на транскрипции. Транскрипцијата ја извршив само на траките за гитара и бас, бидејќи нема смисла за тапани, таму миди тоновите не претставуваат ноти на ист начин како кај останатите инструменти, туку тип на удар и инструмент за удар.

(ЦИТИРАЈ ТРУД ЗА ТРАНСКРИПЦИЈА), (БРОЈКА НА ТРАНСКРИБИРАНИ ПЕСНИ)

\section{Упростување на проблемот}

Вака добвиеното потадочно множество претставуше алгоритамски и технички проблеми за процесот на учење. Најлош случај се јавува кај гитарата. Теоретски во најлош случај можни се 128*127*126*125*124*123=3*10e13 комбинации на ноти според MIDI стандардот, или според физичките ограничувања на гитара 24*6=191.102.976 можни комбинации на ноти. Во еден од експериментите со 50 песни со целосна транскрипција не беше возможно извршивање на моделот бидејки лексиконот напросто експлодираше во големина, па не беше возможно извршување на моделот во меморија, на систем со NVIDIA Tesla K80 со 24GB меморија што е горниот лимит на достапен хардвер. Моделот имаше вкуно (ЦИТИРАЈ БРОЈ НА ВЕЛЗНИ ПАРАМЕТРИ) велзни параметри. Покрај тоа што невозможно за изршување, претпоставувам дека би се разредило, т.е. би се разделиле активациите на премногу елементи, и би било потешко за анализа и дебагирање. Затоа одлучив да изврша консолидација на податочното множество и негово упростување.

\subsection{Поедноставување на акордите, намалување на бројот на можни комбинации}

По пребројување на инстанците од сите комобнации на ноти низ податочното множество увидов дека сите категории на акорди не се подеднакво застапени. Најчесто се појавуваат дурски и молски триади, и рок (познати и како "power") акорди како и поединечни ноти. Во (ЛИНК ДО ТАБЕЛА) може да се види честотата на појавување на акордите по категории. Одлучив да ги заменам акордите чии категории не се појавуваат со повеќе од 1\% со основната нота на акордот, а останатите акорди да ги упростам до 3 нотни верзии. Задржани се акордите од следните категории: (ЛИСТА ОД ФОРТЕ КЛАСИ). Оваа трансформација сметам дека нема премногу да го наруши карактерот на музиката, а сепак ќе ја намали пресметковната комплексност во граници на практична изведба.

(ТАБЕЛА НА ПОЈАВУВАЊА НА ТИПОВИ НА АКОРДИ)

\section{Архитектура за учење}

Архитектурата е имплементирана со користење на Keras библиотеката за длабоко учење, па така некои термини и имиња доаѓаат од терминологијата на библиотеката.
Моделот за учење се состои 3 подмодели, по еден за секој од инструментите. Моделите меѓусебе се идентични, претставени со (ЛИНК ДО ДИЈАГРАМ НА МОДЕЛ). Една влезна рамка за секој од моделите се сотоид од 3 вектори кои ја претставуваат тековно исвирената комбинација на ноти за конкретниот инструмент во временскиот момент кој го претставува рамката. Моделите започнуваат со 3 блока, еден блок кој на влез прима N временски рамки од тековниот временски момент наназад, еден блок на влез ја примат тековната временска рамка, а последниот модел прима N временски рамки нанапред.

Секој од блоковите има излез во тн. ембединг блок (невронска подмрежа) која претставува тесно грло, има помал број на јазлик од претходниот влезен слој, чија задача е да изверши компресија на податоците, и функционира слично на аутоенкодер архитектурата. Ваквите слоеви се искористени претходно во учење на секвенци од зборови (ЦИТИРАЈ ТРУДОВИ ЗА WordEmbeddings) и покрај тоа што прават пресметковно олеснување, учат и веројатности за истровремено појавување на елементите.

По ембединг слојот следуваат 2 LSTM подмрежи и една целосно поврзана мрежа. Излезот од ембединг блоковите одговорни за секвенците од временски рамки оди во LSTM подрежите, додека излезот од ембединг блокот за тековната рамка оди во целосно поврзаната мрежа. LSTM мрежите ги учат временските зависности за соодветниот инструмент врз основа на временските рамки од минатото и иднината, додека целосно поврзаната мрежа ги учи зависностите на тековно исвиреното од соодветниот инструмент и останатите инструменти во даден временски момент. 

Излезите од LSTM мрежите и целосноповрзаната мрежа ги комбинирам во еден велзен вектор за финална целосно поврзана мрежа, чија задача е да ја учи, и подоцна предвиди, тековно отсвирената комбинација ноти за соодветионит инструмент.

\subsection{Ембединг на акорди}

Ембединг блоковите се изградени од цеслосно поврзана невронска мрежа со еден слој од 256 јазли. Влезната димензија на слојот е еднаква на големината на лексиконот, а излезот е реално вредностен вектор од 256 елементи.

(ДИЈАГРАМ ОД СЛОЈ)

\subsection{Основен ЛСТМ мрежа за секвенци}

Двете LSTM мрежи се составени од два слоја по 256 LSTM јазли. Влезната димензија е еднаква на излезот од ембединг слојот помножен со бројот на временски чекори кој се гледа наназад, или нанапред (32), познат како lookback, а излезот е реалновредностен вектор со 256 елементи, со активациска функција тангенс хуперболикус. Излезите ги претставуваат предвидувањата за тековниот чекор врз основа на временскиот сегмент што го надгледува конкретниот блок. Бројот на временски чекори кој се гледа наназад и или нанапред е всушност Back Propagation Through Time, или поточно неговата скратена варијанта Truncated Back Propagation, во Keras одредена со големината на субсеквенца од временски чекори коишто и се даваат на LSTM подмрежата во одреден момент. 
(ДИЈАГРАМ ОД СЛОЈ)

\subsection{Целосно поврзана мрежа за тековната временска рамка}

Овој блок е изграден од еден целосно поврзан слој од 256 јазли. Влезната димезија е еднаква со големината на излезот од ембеинг слојот, а излезот е реално вредностен вектор од 256 елементи, со ReLU (Rectified Linear Unit) активација.

(ДИЈАГРАМ ОД СЛОЈ)

\subsection{Блок за предвиување}

Излезите/предвидувањата од двете LSTM мрежи и целосно поврзаната мрежи ги спојувам во еден поголем вектор кој служи како влез во финалниот блок за предвидување. Овој блок е составен од целосно поврзан слој од број на јазли еднаков на големината на лексиконот. Влезната димензија еднаква на збирот од излезни димензии од претходните блокови за предвидување, а излезот е бинарен вектор со димензија ендаква на големината на лексиконот, со softmax активација. Излезот од овој блок го дава конечното предвидување за вредноста отсвирена од конкретниот инструмент во тековниот временски чекор.

(ДИЈАГРАМ ОД СЛОЈ)

\section{Тренрање на моделот}



\section{Алгоритам за генерирање на песни}

Генерирање на песните го вршам со Псеудо-Гибсова техника за вадење на примероци од веројатносна дистрибуција, заедно со ситем за паралелно ажурирање на вредности (ЦИТИРАЈ PARALLEL GIBBS). Генерирањето започнува со симболот за почеток и трае до предвидување на симбол за крај или до максимална зададена должина на секвенца. Процесот на генерирање е итеративен, т.е. секој претходно предвиден временски чекор влијае на следното предвидување. Техниката предвидува употреба на параметар температура, кој што воведува стохастичност во процесот. Искористив почетна вредност од 1.5 и минимална вредност од 1.0. Колку поголема вредноста има температурата толку е понепредвидлив изборот на следниот елемент во процесот на предвидување, а колку е понизок процесот станува се по-детерминистички. 

\cite{Hadjeres2016} ALGORITHM Generation in dependency networks is performed using the pseudo-Gibbs sampling procedure. This Markov Chain Monte Carlo (MCMC) algorithm is described in Alg.1. It is similar to the classical Gibbs sampling procedure (Geman & Geman, 1984) on the difference that the conditional dis- tributions are potentially incompatible (Chen & Ip, 2015). This means that the conditional distributions of Eq. (2) do not necessarily comes from a joint distribution p(V) and that the theoretical guarantees that the MCMC converges to this stationary joint distribution vanish. We experimen- tally verified that it was indeed the case by checking that the Markov Chain of Alg.1 violatesKolmogorov’s criterion (Kelly, 2011): it is thus not reversible and cannot converge to a joint distribution whose conditional distributions match the ones used for sampling. However, this Markov chain converges to another station- ary distribution and applications on real data demonstrated that this method yielded accurate joint probabilities, espe- cially when the inconsistent probability distributions are learned from data (Heckerman et al., 2000). Furthermore, nonreversible MCMC algorithms can in particular cases be better at sampling that reversible Markov Chains (Vucelja, 2014). 2.3.2. We emphasize on this section the importance of our partic- ular choice of data representation with respect to our sam- pling procedure. The fact that we obtain great results using pseudo-Gibbs sampling relies exclusively on our choice to integrate the hold symbol into the list of notes. Indeed, Gibbs sampling fails to sample the true joint dis-
tribution p(V|M, θ) when variables are highly correlated, creating isolated regions of high probability states in which theMCMCchain can be trapped. However, many data rep- resentations used in music modeling such as
• the piano-roll representation,
• the couple (pitch, articulation) representation where articulation is a Boolean value indicating whether or not the note is played or held,
tend to make the musical data suffer from this drawback.
As an example, in the piano-roll representation, a long note is represented as the repetition of the same value over many variables. In order to only change its pitch, one needs to change simultaneously a large number of variables (which is exponentially rare) while this is achievable with only one variable change with our representation.

\section{Анализа на резултати}

\chapter{Толкување и можност за подобрување}

\chapter{Заклучок}