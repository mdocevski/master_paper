%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Eftim at 2015-04-14 11:36:36 +0200 


%% Saved with string encoding Unicode (UTF-8) 

@article{Sturm2016,
abstract = {We apply deep learning methods, specifically long short-term memory (LSTM) networks, to music transcription modelling and composition. We build and train LSTM networks using approximately 23,000 music transcriptions expressed with a high-level vocabulary (ABC notation), and use them to generate new transcriptions. Our practical aim is to create music transcription models useful in particular contexts of music composition. We present results from three perspectives: 1) at the population level, comparing descriptive statistics of the set of training transcriptions and generated transcriptions; 2) at the individual level, examining how a generated transcription reflects the conventions of a music practice in the training transcriptions (Celtic folk); 3) at the application level, using the system for idea generation in music composition. We make our datasets, software and sound examples open and available: $\backslash$url{\{}https://github.com/IraKorshunova/folk-rnn{\}}.},
archivePrefix = {arXiv},
arxivId = {1604.08723},
author = {Sturm, Bob L. and Santos, Jo{\~{a}}o Felipe and Ben-Tal, Oded and Korshunova, Iryna},
eprint = {1604.08723},
journal = {Conference on Computer Simulation of Musical Creativity},
keywords = {algorithmic composition,deep learning,music modelling,recurrent neural network},
pages = {16},
title = {{Music transcription modelling and composition using deep learning}},
year = {2016}
}

@article{Zils2001,
abstract = {This work addresses the issue of retrieving efficiently sound $\backslash$nsamples in large databases, in the context of digital music $\backslash$ncomposition. We propose a sequence generation mechanism called $\backslash$nmusical mosaicing, which enables to generate automatically $\backslash$nsequences of sound samples by specifying only high-level $\backslash$nproperties of the sequence to generate. The properties of the $\backslash$nsequence specified by the user are translated automatically into $\backslash$nconstraints holding on descriptors of the samples. The system we $\backslash$npropose is able to scale up on databases containing more than $\backslash$n100.000 samples, using a local search method based on constraint $\backslash$nsolving. In this paper, we describe the method for retrieving and $\backslash$nsequencing audio samples, and illustrate it with rhythmic and $\backslash$nmelodic musical sequences. },
author = {Zils, Aymeric and Pachet, Fran{\c{c}}ois},
journal = {Digital Audio Effects (DAFx)},
pages = {1--6},
title = {{Musical mosaicing}},
year = {2001}
}

@article{Yang2017,
abstract = {Most existing neural network models for music generation use recurrent neural networks. However, the recent WaveNet model proposed by DeepMind shows that convolutional neural networks (CNNs) can also generate realistic musical waveforms in the audio domain. Following this light, we investigate using CNNs for generating melody (a series of MIDI notes) one bar after another in the symbolic domain. In addition to the generator, we use a discriminator to learn the distributions of melodies, making it a generative adversarial network (GAN). Moreover, we propose a novel conditional mechanism to exploit available prior knowledge, so that the model can generate melodies either from scratch, by following a chord sequence, or by conditioning on the melody of previous bars (e.g. a priming melody), among other possibilities. The resulting model, named MidiNet, can be expanded to generate music with multiple MIDI channels (i.e. tracks). We conduct a user study to compare the melody of eight-bar long generated by MidiNet and by Google's MelodyRNN models, each time using the same priming melody. Result shows that MidiNet performs comparably with MelodyRNN models in being realistic and pleasant to listen to, yet MidiNet's melodies are reported to be much more interesting.},
archivePrefix = {arXiv},
arxivId = {1703.10847},
author = {Yang, Li-Chia and Chou, Szu-Yu and Yang, Yi-Hsuan},
eprint = {1703.10847},
title = {{MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation}},
year = {2017}
}



@article{Schwarz2006,
abstract = {The concatenative real-time sound synthesis system CataRT plays grains from a large corpus of segmented and descriptor-analysed sounds according to proximity to a target position in the descriptor space. This can be seen as a content-based extension to granular synthesis providing direct access to specific sound characteristics. CataRT is implemented as a collection of Max/MSP patches using the FTM library and an SQL database. Segmentation and MPEG-7 descriptors are loaded from SDIF files or generated on-the-fly. The object-oriented software architecture follows the model–view–controller design pattern. CataRT allows to explore the corpus interactively or via a target sequencer, to resynthesise an audio file or live input with the source sounds, or to experiment with expressive speech synthesis and gestural control.},
author = {Schwarz, Diemo and Gr{\'{e}}gory, Beller and Bruno, Verbrugghe and Sam, Britton},
journal = {Proc. of the 9th Int. Conference on Digital Audio Effects (DAFx-06)},
number = {September},
pages = {1--7},
title = {{Real-time corpus-based concatenative synthesis with CataRT}},
year = {2006}
}



@article{GarciaSalas2011,
author = {{Garc{\'{i}}a Salas}, Horacio Alberto and Gelbukh, Alexander and Calvo, Hiram and Soria, Fernando Galindo},
journal = {Polibits},
pages = {59--65},
title = {{Automatic Music Composition with Simple Probabilistic Generative Grammars}},
volume = {44},
year = {2011}
}

@article{Biles1994,
abstract = {This paper describes GenJam, a genetic algorithm-based model of a novice jazz musician learning to improvise. GenJam maintains hierarchically related populations of melodic ideas that are mapped to specific notes through scales suggested by the chord progression being played. As GenJam plays its solos over the accompaniment of a standard rhythm section, a human mentor gives real-time feedback, which is used to derive fitness values for the individual measures and phrases. GenJam then applies various genetic operators to the populations to breed improved generations of ideas.},
author = {Biles, John a.},
isbn = {1026-1087},
issn = {1026-1087},
journal = {Proceedings of the International Computer Music Conference},
pages = {131--137},
title = {{GenJam: A genetic algorithm for generating jazz solos}},
year = {1994}
}

@article{Cope1991,
author = {Cope, David},
journal = {Computer - Special issue: Computer-generated music},
number = {7},
pages = {22--28},
title = {{Recombinant music using the computer to explore musical style}},
volume = {24},
year = {1991}
}

@article{Oord2016,
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
archivePrefix = {arXiv},
arxivId = {1609.03499},
author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
doi = {10.1109/ICASSP.2009.4960364},
eprint = {1609.03499},
isbn = {9783901882760},
issn = {0899-7667},
pages = {1--15},
pmid = {18785855},
title = {{WaveNet: A Generative Model for Raw Audio}},
year = {2016}
}

@article{Tikhonov2017,
abstract = {A serious problem for automated music generation is to propose the model that could reproduce sophisticated temporal and melodic patterns that would correspond to the style of the training input. We propose a new architecture of an artificial neural network that helps to deal with such tasks. The proposed approach is based on a long short-term memory language model combined with variational recurrent autoencoder. These methods have certain advantages when dealing with temporally rich inputs. The proposed architecture comprises this features and helps to generate results of higher complexity and diversity.},
archivePrefix = {arXiv},
arxivId = {1705.05458},
author = {Tikhonov, Alexey and Yamshchikov, Ivan P.},
eprint = {1705.05458},
keywords = {artificial intelligence,variational recurrent autoencoder},
pages = {1--11},
title = {{Music generation with variational recurrent autoencoder supported by history}},
year = {2017}
}


@article{Boulanger-Lewandowski2012,
abstract = {We investigate the problem of modeling symbolic sequences of polyphonic music in a completely general piano-roll representation. We introduce a probabilistic model based on distribution estimators conditioned on a recurrent neural network that is able to discover temporal dependencies in high-dimensional sequences. Our approach outperforms many traditional models of polyphonic music on a variety of realistic datasets. We show how our musical language model can serve as a symbolic prior to improve the accuracy of polyphonic transcription.},
archivePrefix = {arXiv},
arxivId = {1206.6392},
author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
eprint = {1206.6392},
isbn = {978-1-4503-1285-1},
number = {Cd},
title = {{Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription}},
year = {2012}
}

@article{Boulanger-Lewandowski2014,
abstract = {This thesis focuses on advancing the state of the art in sequence modeling, and thereby improving several applications in the area of polyphonic music and speech, namely polyphonic music generation and transcription, audio chord recognition, speech recognition and audio source separation. Modeling real-world sequences often involves capturing long-term dependencies between the high-dimensional objects that compose such sequences. This problem is in general too dicult to tackle by manually engineering rules to process the data in each possible scenario and we instead follow a machine learning approach.},
author = {Boulanger-Lewandowski, Nicolas},
isbn = {9782951677319},
pages = {145},
title = {{Modeling High-Dimensional Audio Sequences with Recurrent Neural Networks}},
year = {2014}
}


@article{Goel2014,
abstract = {In this paper, we propose a generic technique to model temporal dependencies and sequences using a combination of a recurrent neural network and a Deep Belief Network. Our technique, RNN-DBN, is an amalgamation of the memory state of the RNN that allows it to provide temporal information and a multi-layer DBN that helps in high level representation of the data. This makes RNN-DBNs ideal for sequence generation. Further, the use of a DBN in conjunction with the RNN makes this model capable of significantly more complex data representation than an RBM. We apply this technique to the task of polyphonic music generation.},
archivePrefix = {arXiv},
arxivId = {1412.7927},
author = {Goel, Kratarth and Vohra, Raunaq and Sahoo, J. K.},
doi = {10.1007/978-3-319-11179-7_28},
eprint = {1412.7927},
isbn = {9783319111780},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Deep Belief Networks,Deep architectures,creative machine learning,generative models,music generation,recurrent neural networks},
pages = {217--224},
title = {{Polyphonic music generation by modeling temporal dependencies using a RNN-DBN}},
volume = {8681 LNCS},
year = {2014}
}


@article{Johnson2017,
abstract = {We describe a neural network architecture designed to learn the musical structure of jazz melodies over chord progressions, then to create new melodies over arbi-trary chord progressions from the resulting connectome (representation of neural network structure). Our ar-chitecture consists of two sub-networks, the interval expert and the chord expert, each being LSTM (long short-term memory) recurrent networks. These two sub-networks jointly learn to predict a probability dis-tribution over future notes conditioned on past notes in the melody. We describe a training procedure for the network and an implementation as part of the open-source Impro-Visor (Improvisation Advisor) applica-tion, and demonstrate our method by providing impro-vised melodies based on a variety of training sets.},
author = {Johnson, Daniel D and Keller, Robert M and Weintraut, Nicholas},
journal = {Eighth International Conference on Computational Creativity (ICCC'17)},
pages = {151--158},
title = {{Learning to Create Jazz Melodies Using a Product of Experts}},
year = {2017}
}

@misc{AndrejKarpathy2015,
author = {{Andrej Karpathy}},
title = {{The Unreasonable Effectiveness of Recurrent Neural Networks}},
url = {https://karpathy.github.io/2015/05/21/rnn-effectiveness/},
urldate = {2018-01-23},
year = {2015}
}

@article{Eck2002,
abstract = {In general music composed by recurrent neural networks (RNNs) suffers from a lack of global structure. Though networks can learn note-by-note transition probabilities and even reproduce phrases, attempts at learning an entire musical form and using that knowledge to guide composition have been unsuccessful. The reason for this failure seems to be that RNNs cannot keep track of temporally distant events that indicate global music structure. Long Short-Term Memory (LSTM) has succeeded in similar domains where other RNNs have failed, such as timing {\&} counting and CSL learning. In the current study we show that LSTM is also a good mechanism for learning to compose music. We compare this approach to previous attempts, with particular focus on issues of data representation. We present experimental results showing that LSTM successfully learns a form of blues music and is able to compose novel (and we believe pleasing) melodies in that style. Remarkably, once the network has found the relevant structure it does not drift from it: LSTM is able to play the blues with good timing and proper structure as long as one is willing to listen.},
author = {Eck, Douglas and Schmidhuber, J{\"{u}}rgen},
journal = {Idsia},
pages = {1--11},
title = {{A First Look at Music Composition using LSTM Recurrent Neural Networks}},
year = {2002}
}

@article{Eck2008,
abstract = {This paper addresses the challenge of learning global musical structure from databases of music sequences. We introduce a music-specific sequence learner that combines an LSTM recur-rent neural network with an autocorrelation-based predictor of metrical structure. The model is able to learn arbitrary long-timescale correlations in music but is biased towards finding cor-relations that are aligned with the meter of the piece. This biasing allows the model to work with low learning capacity and thus to avoid overfitting. In a set of simulations we show that the model can learn the global temporal structure of a musical style by simply trying to predict the next note in a set of pieces selected from that style. To test whether global structure has in fact been been learned, we use the model to generate new pieces of music in that style. In a discussion of the model we highlight its sensitivity to three distinct levels of temporal order in music corresponding to local structure, long-timescale metrical structure and long-timescale non-metrical structure.},
author = {Eck, Douglas and Lapalme, Jasmin},
journal = {University of Montreal, Department of Computer {\ldots}},
number = {1983},
pages = {1--12},
title = {{Learning musical structure directly from sequences of music}},
year = {2008}
}

@article{Hadjeres2016,
abstract = {This paper introduces DeepBach, a graphical model aimed at modeling polyphonic music and specifically hymn-like pieces. We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach. DeepBach's strength comes from the use of pseudo-Gibbs sampling coupled with an adapted representation of musical data. This is in contrast with many automatic music composition approaches which tend to compose music sequentially. Our model is also steerable in the sense that a user can constrain the generation by imposing positional constraints such as notes, rhythms or cadences in the generated score. We also provide a plugin on top of the MuseScore music editor making the interaction with DeepBach easy to use.},
archivePrefix = {arXiv},
arxivId = {1612.01010},
author = {Hadjeres, Ga{\"{e}}tan and Pachet, Fran{\c{c}}ois and Nielsen, Frank},
eprint = {1612.01010},
isbn = {4573196480018},
title = {{DeepBach: a Steerable Model for Bach Chorales Generation}},
year = {2016}
}


@article{Liang2017,
abstract = {This paper presents " BachBot " : an end-to-end automatic composition system for composing and completing mu-sic in the style of Bach's chorales using a deep long short-term memory (LSTM) generative model. We pro-pose a new sequential encoding scheme for polyphonic music and a model for both composition and harmoniza-tion which can be efficiently sampled without expensive Markov Chain Monte Carlo (MCMC). Analysis of the trained model provides evidence of neurons specializing without prior knowledge or explicit supervision to detect common music-theoretic concepts such as tonics, chords, and cadences. To assess BachBot's success, we conducted one of the largest musical discrimination tests on 2336 par-ticipants. Among the results, the proportion of responses correctly differentiating BachBot from Bach was only 1{\%} better than random guessing.},
author = {Liang, Feynman and Gotham, Mark and Johnson, Matthew and Shotton, Jamie},
journal = {Proceedings of the 18th International Society for Music Information Retrieval Conference},
pages = {449--456},
title = {{Automatic Stylistic Composition of Bach Chorales with Deep LSTM}},
year = {2017}
}

@article{Johnson2017,
abstract = {We describe a neural network architecture which enables prediction and composition of polyphonic music in a manner that preserves translation-invariance of the dataset. Specifically, we demonstrate training a probabilistic model of polyphonic music using a set of parallel, tied-weight recurrent networks, inspired by the structure of convolutional neural networks. This model is designed to be invariant to transpositions, but otherwise is intentionally given minimal in-formation about the musical domain, and tasked with discovering patterns present in the source dataset. We present two versions of the model, denoted TP-LSTM-NADE and BALSTM, and also give methods for training the network and for generating novel music. This approach attains high performance at a musical pre-diction task and successfully creates note sequences which possess measure-level musical structure.},
author = {Johnson, Daniel D.},
doi = {10.1007/978-3-319-55750-2_9},
isbn = {9783319557496},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {128--143},
title = {{Generating polyphonic music using tied parallel networks}},
volume = {10198 LNCS},
year = {2017}
}

@article{Bretan2016,
abstract = {Several methods exist for a computer to generate music based on data including Markov chains, recurrent neural networks, recombinancy, and grammars. We explore the use of unit selection and concatenation as a means of generating music using a procedure based on ranking, where, we consider a unit to be a variable length number of measures of music. We first examine whether a unit selection method, that is restricted to a finite size unit library, can be sufficient for encompassing a wide spectrum of music. We do this by developing a deep autoencoder that encodes a musical input and reconstructs the input by selecting from the library. We then describe a generative model that combines a deep structured semantic model (DSSM) with an LSTM to predict the next unit, where units consist of four, two, and one measures of music. We evaluate the generative model using objective metrics including mean rank and accuracy and with a subjective listening test in which expert musicians are asked to complete a forced-choiced ranking task. We compare our model to a note-level generative baseline that consists of a stacked LSTM trained to predict forward by one note.},
archivePrefix = {arXiv},
arxivId = {1612.03789},
author = {Bretan, Mason and Weinberg, Gil and Heck, Larry},
eprint = {1612.03789},
pages = {1--13},
title = {{A Unit Selection Methodology for Music Generation Using Deep Neural Networks}},
year = {2016}
}

@article{Sturm2015,
abstract = {We demonstrate two generative models created by train-ing a recurrent neural network (RNN) with three hidden layers of long short-term memory (LSTM) units. This ex-tends past work in numerous directions, including training deeper models with nearly 24,000 high-level transcriptions of folk tunes. We discuss our on-going work.},
author = {Sturm, Bob L and Santos, Jo{\~{a}}o Felipe and Korshunova, Iryna},
journal = {Ismir},
title = {{Folk Music Style Modelling By Recurrent Neural Networks With Long Short Term Memory Units}},
year = {2015}
}

@article{Madjiheurem2016,
abstract = {In natural language processing, the well-known Skip-gram model learns vector representations of words that carry meaningful syntactic and semantic information. In our work, we investigate whether similar high-quality embeddings can be found for symbolic music data. We introduce three NLP inspired models to learn vector representations of chords and we evaluate their performance. We show that an adaptation of the sequence-to-sequence model is by far superior to the other proposed model.},
author = {Madjiheurem, Sephora and Qu, Lizhen and Walder, Christian},
number = {Nips},
title = {{Chord2Vec: Learning Musical Chord Embeddings}},
year = {2016}
}

@article{Cho2014,
abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
archivePrefix = {arXiv},
arxivId = {1406.1078},
author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
doi = {10.3115/v1/D14-1179},
eprint = {1406.1078},
isbn = {9781937284961},
issn = {09205691},
pmid = {2079951},
title = {{Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}},
year = {2014}
}

@article{Walder2016,
abstract = {In this paper, we consider the problem of probabilistically modelling symbolic music data. We introduce a representation which reduces polyphonic music to a univariate categorical sequence. In this way, we are able to apply state of the art natural language processing techniques, namely the long short-term memory sequence model. The representation we employ permits arbitrary rhythmic structure, which we assume to be given. We show that our model is effective on four out of four piano roll based benchmark datasets. We further improve our model by augmenting our training data set with transpositions of the original pieces through all musical keys, thereby convincingly advancing the state of the art on these benchmark problems. We also fit models to music which is unconstrained in its rhythmic structure, discuss the properties of this model, and provide musical samples which are more sophisticated than previously possible with this class of recurrent neural network sequence models. We also provide our newly preprocessed data set of non piano-roll music data.},
archivePrefix = {arXiv},
arxivId = {1606.01368},
author = {Walder, Christian},
eprint = {1606.01368},
title = {{Modelling Symbolic Music: Beyond the Piano Roll}},
year = {2016}
}

@article{Ghedini2015,
abstract = {This chapter introduces the vision and the technical challenges of the Flow Machines project. Flow Machines aim at fostering creativity in artistic domains such as music and literature. We first observe that typically, great artists do not output just single artefacts but develop novel, individual styles. Style mirrors an individual's uniqueness; style makes an artist's work recognised and recognisable. Artists develop their own style after prolonged periods of imitation and exploration of the style of others. We envision style exploration as the application of existing styles, considered as texture, to arbitrary constraints, considered as structure. The goal of Flow Machines is to assist this process by allowing users to explicitly manipulate styles as computational objects. During interactions with Flow Machines, the user can create artefacts (melodies, texts, orchestrations) by combining styles with arbitrary constraints. Style exploration under user-defined constraints raises complex sequence generation issues that were addressed and solved for the most part during the first half of the project. We illustrate the potential of these techniques for style exploration with three examples.},
author = {Ghedini, Fiammetta and Pachet, Fran{\c{c}}ois and Roy, Pierre},
doi = {10.1007/978-981-287-618-8_18},
isbn = {9789812876188},
journal = {Multidisciplinary Contributions to the Science of Creative Thinking},
pages = {325--343},
title = {{Creating music and texts with flow machines}},
year = {2015}
}

%% STARO

@article{provost2013data,
  title={Data science and its relationship to big data and data-driven decision making},
  author={Provost, Foster and Fawcett, Tom},
  journal={Big data},
  volume={1},
  number={1},
  pages={51--59},
  year={2013},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}

@misc{jacobi2011recommendation,
  title={Recommendation system},
  author={Jacobi, Jennifer A and Benson, Eric A and Linden, Gregory D},
  year={2011},
  month=mar # "~15",
  publisher={Google Patents},
  note={US Patent 7,908,183}
}

@inproceedings{davidson2010youtube,
  title={The YouTube video recommendation system},
  author={Davidson, James and Liebald, Benjamin and Liu, Junning and Nandy, Palash and Van Vleet, Taylor and Gargi, Ullas and Gupta, Sujoy and He, Yu and Lambert, Mike and Livingston, Blake and others},
  booktitle={Proceedings of the fourth ACM conference on Recommender systems},
  pages={293--296},
  year={2010},
  organization={ACM}
}

@article{geva2014empirical,
  title={Empirical evaluation of an automated intraday stock recommendation system incorporating both market data and textual news},
  author={Geva, Tomer and Zahavi, Jacob},
  journal={Decision support systems},
  volume={57},
  pages={212--223},
  year={2014},
  publisher={Elsevier}
}

@article{bollen2011twitter,
  title={Twitter mood predicts the stock market},
  author={Bollen, Johan and Mao, Huina and Zeng, Xiaojun},
  journal={Journal of computational science},
  volume={2},
  number={1},
  pages={1--8},
  year={2011},
  publisher={Elsevier}
}

@article{kaunitz2017beating,
  title={Beating the bookies with their own numbers-and how the online sports betting market is rigged},
  author={Kaunitz, Lisandro and Zhong, Shenjun and Kreiner, Javier},
  journal={arXiv preprint arXiv:1710.02824},
  year={2017}
}

@article{anastasovskirazliki,
  title={Разлики помеѓу спортско обложување и коцкање од аспект на образовно ниво на граѓани кои се активни корисници на игрите на среќа во Република Македонија},
  author={Анастасовски}
}

@incollection{zdravevski2010system,
  title={System for Prediction of the Winner in a Sports Game},
  author={Zdravevski, Eftim and Kulakov, Andrea},
  booktitle={ICT Innovations 2009},
  pages={55--63},
  year={2010},
  publisher={Springer}
}

@inproceedings{odachowski2012using,
  title={Using bookmaker odds to predict the final result of football matches},
  author={Odachowski, Karol and Grekow, Jacek},
  booktitle={International Conference on Knowledge-Based and Intelligent Information and Engineering Systems},
  pages={196--205},
  year={2012},
  organization={Springer}
}

@inproceedings{odachowski2012predicting,
  title={Predicting the Final Result of Sporting Events Based on Changes in Bookmaker Odds.},
  author={Odachowski, Karol and Grekow, Jacek},
  booktitle={KES},
  pages={278--287},
  year={2012}
}

@article{haghighat2013review,
  title={A review of data mining techniques for result prediction in sports},
  author={Haghighat, Maral and Rastegari, Hamid and Nourafza, Nasim},
  journal={Advances in Computer Science: an International Journal},
  volume={2},
  number={5},
  pages={7--12},
  year={2013}
}

@inproceedings{ivankovic2010analysis,
  title={Analysis of basketball games using neural networks},
  author={Ivankovi{\'c}, Z and Rackovi{\'c}, M and Markoski, Branko and Radosav, D and Ivkovi{\'c}, M},
  booktitle={Computational Intelligence and Informatics (CINTI), 2010 11th International Symposium on},
  pages={251--256},
  year={2010},
  organization={IEEE}
}

@article{cheng2016predicting,
  title={Predicting the outcome of NBA playoffs based on the maximum entropy principle},
  author={Cheng, Ge and Zhang, Zhenyu and Kyebambe, Moses Ntanda and Kimbugwe, Nasser},
  journal={Entropy},
  volume={18},
  number={12},
  pages={450},
  year={2016},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{pachur2007forecasting,
  title={Forecasting from ignorance: The use and usefulness of recognition in lay predictions of sports events},
  author={Pachur, Thorsten and Biele, Guido},
  journal={Acta Psychologica},
  volume={125},
  number={1},
  pages={99--116},
  year={2007},
  publisher={Elsevier}
}

@article{leitner2010forecasting,
  title={Forecasting sports tournaments by ratings of (prob) abilities: A comparison for the EURO 2008},
  author={Leitner, Christoph and Zeileis, Achim and Hornik, Kurt},
  journal={International Journal of Forecasting},
  volume={26},
  number={3},
  pages={471--481},
  year={2010},
  publisher={Elsevier}
}

@article{tax2015predicting,
  title={Predicting the Dutch football competition using public data: A machine learning approach},
  author={Tax, Niek and Joustra, Yme},
  journal={Transactions on Knowledge and Data Engineering},
  volume={10},
  number={10},
  pages={1--13},
  year={2015}
}

@online{football-data,
  author = {Football-Data.co.uk},
  title = {Historical Football Results and Betting Odds Data},
  url = {http://www.football-data.co.uk/data.php},
  urldate = {2018-03-11}
}

@article{mingov2016application,
  title={Application of Russian Language Phonemics to Generate Macedonian Speech Recognition Model Using Sphinx},
  author={Mingov, Riste and Zdravevski, Eftim and Lameski, Petre},
  journal={ICT Innovations},
  year={2016}
}

@inproceedings{wang2012test,
  title={A test automation framework based on WEB},
  author={Wang, Fei and Du, Wencai},
  booktitle={Computer and Information Science (ICIS), 2012 IEEE/ACIS 11th International Conference on},
  pages={683--687},
  year={2012},
  organization={IEEE}
}

@book{momjian2001postgresql,
  title={PostgreSQL: introduction and concepts},
  author={Momjian, Bruce},
  volume={192},
  year={2001},
  publisher={Addison-Wesley New York}
}

@inproceedings{rish2001empirical,
  title={An empirical study of the naive Bayes classifier},
  author={Rish, Irina},
  booktitle={IJCAI 2001 workshop on empirical methods in artificial intelligence},
  volume={3},
  number={22},
  pages={41--46},
  year={2001},
  organization={IBM}
}

@book{hosmer2013applied,
  title={Applied logistic regression},
  author={Hosmer Jr, David W and Lemeshow, Stanley and Sturdivant, Rodney X},
  volume={398},
  year={2013},
  publisher={John Wiley \& Sons}
}

@article{cortes1995support,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  number={3},
  pages={273--297},
  year={1995},
  publisher={Springer}
}

@article{breiman2001random,
  title={Random Forests Machine Learning. 45: 5--32},
  author={Breiman, L},
  journal={View Article PubMed/NCBI Google Scholar},
  year={2001}
}

@article{geurts2006extremely,
  title={Extremely randomized trees},
  author={Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
  journal={Machine learning},
  volume={63},
  number={1},
  pages={3--42},
  year={2006},
  publisher={Springer}
}

@incollection{lameski2015svm,
  title={SVM parameter tuning with grid search and its impact on reduction of model over-fitting},
  author={Lameski, Petre and Zdravevski, Eftim and Mingov, Riste and Kulakov, Andrea},
  booktitle={Rough Sets, Fuzzy Sets, Data Mining, and Granular Computing},
  pages={464--474},
  year={2015},
  publisher={Springer}
}

@inproceedings{zdravevski2015robust,
  title={Robust histogram-based feature engineering of time series data},
  author={Zdravevski, Eftim and Lameski, Petre and Mingov, Riste and Kulakov, Andrea and Gjorgjevikj, Dejan},
  booktitle={Computer Science and Information Systems (FedCSIS), 2015 Federated Conference on},
  pages={381--388},
  year={2015},
  organization={IEEE}
}

@book{schalkoff1997artificial,
  title={Artificial neural networks},
  author={Schalkoff, Robert J},
  volume={1},
  year={1997},
  publisher={McGraw-Hill New York}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{fussell1975hand,
  title={How to hand-calculate system reliability and safety characteristics},
  author={Fussell, JB},
  journal={IEEE Transactions on Reliability},
  volume={24},
  number={3},
  pages={169--174},
  year={1975},
  publisher={IEEE}
}